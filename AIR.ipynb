{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwEr46hqDtJK",
    "outputId": "311084f7-f109-4a2f-8087-0c085942a63c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wget in /home/niklas/.local/lib/python3.10/site-packages (3.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/niklas/.local/lib/python3.10/site-packages (4.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/niklas/.local/lib/python3.10/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/niklas/.local/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/niklas/.local/lib/python3.10/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/niklas/.local/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/niklas/.local/lib/python3.10/site-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/niklas/.local/lib/python3.10/site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/niklas/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.1.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ray in /home/niklas/.local/lib/python3.10/site-packages (2.2.0)\n",
      "Requirement already satisfied: packaging in /home/niklas/.local/lib/python3.10/site-packages (from ray) (21.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /home/niklas/.local/lib/python3.10/site-packages (from ray) (1.23.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray) (3.8.0)\n",
      "Requirement already satisfied: attrs in /home/niklas/.local/lib/python3.10/site-packages (from ray) (22.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from ray) (5.4.1)\n",
      "Requirement already satisfied: frozenlist in /home/niklas/.local/lib/python3.10/site-packages (from ray) (1.3.3)\n",
      "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.10/dist-packages (from ray) (20.16.7)\n",
      "Requirement already satisfied: jsonschema in /home/niklas/.local/lib/python3.10/site-packages (from ray) (4.17.0)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/niklas/.local/lib/python3.10/site-packages (from ray) (4.21.12)\n",
      "Requirement already satisfied: aiosignal in /home/niklas/.local/lib/python3.10/site-packages (from ray) (1.3.1)\n",
      "Requirement already satisfied: grpcio>=1.42.0 in /home/niklas/.local/lib/python3.10/site-packages (from ray) (1.51.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/niklas/.local/lib/python3.10/site-packages (from ray) (1.0.4)\n",
      "Requirement already satisfied: click>=7.0 in /usr/lib/python3/dist-packages (from ray) (8.0.3)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.24->ray) (0.3.6)\n",
      "Requirement already satisfied: platformdirs<3,>=2.4 in /home/niklas/.local/lib/python3.10/site-packages (from virtualenv>=20.0.24->ray) (2.5.4)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/niklas/.local/lib/python3.10/site-packages (from jsonschema->ray) (0.19.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging->ray) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2022.12.7)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/niklas/.local/lib/python3.10/site-packages (1.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/niklas/.local/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/niklas/.local/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/niklas/.local/lib/python3.10/site-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/niklas/.local/lib/python3.10/site-packages (from scikit-learn) (1.23.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install wget\n",
    "!pip install transformers\n",
    "!pip install ray\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "N1mZmWzU18_W"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import wget\n",
    "import gzip\n",
    "import html\n",
    "import tarfile\n",
    "import logging\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, AdamW, BertTokenizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mCd6h66j7mKf"
   },
   "outputs": [],
   "source": [
    "class ProductRanker(nn.Module):\n",
    "    def __init__(self, l1=128, l2=32):\n",
    "        super(ProductRanker, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        self.ranker = nn.Sequential(\n",
    "            nn.Linear(768, l1),\n",
    "            nn.BatchNorm1d(l1, affine=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(l1, l2),\n",
    "            nn.BatchNorm1d(l2, affine=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(l2,1)\n",
    "        )\n",
    "\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "        logits = self.ranker(last_hidden_state_cls)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tA9ILTLDDmkE",
    "outputId": "b5312e23-ee29-4c5c-891f-66d677b616d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niklas/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: HIP initialization: Unexpected error from hipGetDeviceCount(). Did you run some cuda functions before calling NumHipDevices() that might have already set an error? Error 101: hipErrorInvalidDevice (Triggered internally at ../c10/hip/HIPFunctions.cpp:110.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#Constants\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config = {'l1': 128, 'l2': 32, 'lr': 0.0005, 'batch_size': 100}\n",
    "model = ProductRanker(config[\"l1\"],config[\"l2\"]).to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"], betas=(0.9, 0.999), eps=1e-08, weight_decay=0,\n",
    "                            amsgrad=False)\n",
    "cos = torch.nn.CosineSimilarity(dim=0)\n",
    "\n",
    "if not os.path.exists(\"./data\"):\n",
    "    os.makedirs(\"./data\")\n",
    "if not os.path.exists(\"./outputs\"):\n",
    "    os.makedirs(\"./outputs\")\n",
    "\n",
    "logging.basicConfig(filename='./outputs/training.log', filemode='w', format='%(asctime)s %(message)s', level=logging.DEBUG, force=True)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "g35D5YJf3Ila"
   },
   "outputs": [],
   "source": [
    "def downloadData(url, path):\n",
    "    return wget.download(url, out=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "V4-NKG6m3OjZ"
   },
   "outputs": [],
   "source": [
    "def loadJson(filename):\n",
    "    data = []\n",
    "    with gzip.open(filename, \"rt\") as f:\n",
    "        for line in f:\n",
    "            stripped = line.strip()\n",
    "            stripped = stripped.replace(\"\\'\", \"\\\"\")\n",
    "            try:\n",
    "                data.append(json.loads(stripped))\n",
    "            except json.decoder.JSONDecodeError:\n",
    "                continue \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CZatCtPg3QRz"
   },
   "outputs": [],
   "source": [
    "def filterJson(data, extrema_dict):\n",
    "    filtered = []\n",
    "    for entry in data:\n",
    "        if not isGoodJsonEntry(entry):\n",
    "            continue\n",
    "        \n",
    "        sales_rank_key = list(entry['salesRank'].keys())[0]\n",
    "        sales_rank_value = entry['salesRank'][sales_rank_key]\n",
    "        min = extrema_dict[sales_rank_key][0]\n",
    "        max = extrema_dict[sales_rank_key][1]\n",
    "\n",
    "        tmp = {}\n",
    "        if min == max:\n",
    "            tmp['salesRank'] = 0.5\n",
    "        else:\n",
    "            tmp['salesRank'] = (sales_rank_value - min) / (max - min)\n",
    "        tmp['description'] = html.unescape(entry['description'])\n",
    "        filtered.append(tmp)\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uFHxm4vW3TU6"
   },
   "outputs": [],
   "source": [
    "def getExtremaDict(data):\n",
    "    extrema_dict = {}\n",
    "    for entry in data:\n",
    "        if not isGoodJsonEntry(entry):\n",
    "            continue\n",
    "\n",
    "        sales_rank_key = list(entry['salesRank'].keys())[0]\n",
    "        sales_rank_value = entry['salesRank'][sales_rank_key]\n",
    "        if sales_rank_key not in extrema_dict:\n",
    "            extrema_dict[sales_rank_key] = [sales_rank_value, sales_rank_value] \n",
    "        else:\n",
    "            if extrema_dict[sales_rank_key][0] > sales_rank_value:\n",
    "                extrema_dict[sales_rank_key][0] = sales_rank_value\n",
    "            elif extrema_dict[sales_rank_key][1] < sales_rank_value:\n",
    "                extrema_dict[sales_rank_key][1] = sales_rank_value\n",
    "\n",
    "    return extrema_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lUCHiFQx3Vjo"
   },
   "outputs": [],
   "source": [
    "def isGoodJsonEntry(entry):\n",
    "    if 'description' not in entry.keys():\n",
    "        return False\n",
    "    if len(entry['description']) == 0:\n",
    "        return False\n",
    "    if 'salesRank' not in entry.keys():\n",
    "        return False\n",
    "    if len(entry['salesRank']) == 0:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "iYBaprFg3YFW"
   },
   "outputs": [],
   "source": [
    "def safeJson(filtered, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for object in filtered:\n",
    "            json.dump(object, f)\n",
    "            f.write(os.linesep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Qxt6iaSp3Zmv"
   },
   "outputs": [],
   "source": [
    "def getJSON(data_dir=\"./data\"):\n",
    "    filename_meta = os.path.join(data_dir, \"meta_Electronics.json.gz\")\n",
    "    filename_filtered_meta = os.path.join(data_dir, \"filtered_meta_Electronics.tar.gz\")\n",
    "    filename_destination_meta_train = os.path.join(data_dir, \"filtered_meta_Electronics_train.json\")\n",
    "    filename_destination_meta_test = os.path.join(data_dir, \"filtered_meta_Electronics_test.json\")\n",
    "\n",
    "    url_meta = \"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/meta_Electronics.json.gz\"\n",
    "    \n",
    "    if os.path.exists(filename_destination_meta_train) and os.path.exists(filename_destination_meta_test):\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(filename_meta):\n",
    "        downloadData(url_meta, filename_meta)\n",
    "    \n",
    "    data = loadJson(filename_meta)\n",
    "    extrema_dict = getExtremaDict(data)\n",
    "    filtered = filterJson(data, extrema_dict)\n",
    "    safeJson(filtered, filename_destination_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGoogleWord2Vec():\n",
    "    return api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "model_word2vec = loadGoogleWord2Vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averagePollingDocument(model_word2vec, data_dir=\"./data\"):\n",
    "    path = os.path.join(data_dir, \"filtered_meta_Electronics.json\")\n",
    "    df = pd.read_json(path, lines=True) \n",
    "    \n",
    "    len_vec = len(model_word2vec[\"hello\"])\n",
    "    \n",
    "    documents = dict()\n",
    "    for index, row in df.iterrows():\n",
    "        tmp = torch.zeros(len_vec)\n",
    "        description = utils.simple_preprocess(row['description'])\n",
    "        for word in description:\n",
    "            try:\n",
    "                tmp = tmp.add(torch.tensor(model_word2vec[word]))\n",
    "            except KeyError:\n",
    "                continue\n",
    "        documents[index] = tmp.div(len(description))\n",
    "        \n",
    "    return documents\n",
    "\n",
    "documents = averagePollingDocument(model_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor(0.4788), 8750), (tensor(0.4092), 15011), (tensor(0.4070), 17988)]\n"
     ]
    }
   ],
   "source": [
    "def averagePollingQuery(query, model_word2vec):\n",
    "    query = utils.simple_preprocess(query)\n",
    "    len_vec = len(model_word2vec[\"hello\"])\n",
    "    \n",
    "    avg_query = torch.zeros(len_vec)\n",
    "    for word in query:\n",
    "        try:\n",
    "            avg_query += avg_query.add(torch.tensor(model_word2vec[word]))\n",
    "        except KeyError:\n",
    "            continue\n",
    "    avg_query = avg_query / len(query)\n",
    "    return avg_query\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMostSimilair(avg_query, documents, x=10):\n",
    "    avg_query = averagePollingQuery(\"test test HELLO\", model_word2vec)\n",
    "    cosine_sim = [(cos(avg_query, value), indx) for indx, value in documents.items()]\n",
    "    cosine_sim.sort(key=lambda y: -y[0].item())\n",
    "    most_similair = cosine_sim[:x]\n",
    "    return most_similair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "eMavKxtY8Bv6"
   },
   "outputs": [],
   "source": [
    "def dataPreparation(data_dir=\"./data\"):\n",
    "    path = os.path.join(data_dir, \"filtered_meta_Electronics_train.json\")\n",
    "    df = pd.read_json(path, lines=True).sample(n = (225))\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    tokenized_set = []\n",
    "    for index, row in df.iterrows():\n",
    "        tokenized_set.append([tokenizer.encode_plus(row['description'], truncation = True, return_tensors=\"pt\",\n",
    "                                                    max_length=512, pad_to_max_length=True), row['salesRank']])\n",
    "    return torch.utils.data.random_split(tokenized_set, [150, 75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_-y6YFzn8SWW"
   },
   "outputs": [],
   "source": [
    "def createDataloader(dataset, config, shuffle=True, test=False):\n",
    "    labeled_set = []\n",
    "    if test:\n",
    "        for i, doc1 in enumerate(dataset):\n",
    "            labeled_set.append([[doc1[0]], doc1[1]])\n",
    "    else:\n",
    "        for i, doc1 in enumerate(dataset):\n",
    "            for j, doc2 in enumerate(dataset):\n",
    "                if i != j:\n",
    "                    label = 0.0\n",
    "                    if doc1[1] > doc2[1]:\n",
    "                        label = 1.0\n",
    "                    if doc1[1] == doc2[1]:\n",
    "                        label = 0.5\n",
    "\n",
    "                    labeled_set.append([[doc1[0], doc2[0]], label])\n",
    "    return torch.utils.data.DataLoader(labeled_set, batch_size=int(config[\"batch_size\"]), num_workers=2, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "f7k5M2SU8Zw8"
   },
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, dataloader, epoch, saving=False, tune=False):\n",
    "    running_loss = 0.0\n",
    "    epoch_steps = 0\n",
    "\n",
    "    train_loss = 0.0\n",
    "    acc_tp_tn = 0\n",
    "    acc_total = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for X,y in dataloader:\n",
    "        input_ids_1 = X[0]['input_ids'].squeeze().to(device)\n",
    "        attention_mask_1 = X[0]['attention_mask'].squeeze().to(device)\n",
    "        input_ids_2 = X[1]['input_ids'].squeeze().to(device)\n",
    "        attention_mask_2 = X[1]['attention_mask'].squeeze().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out1 = model.forward(input_ids_1, attention_mask_1)\n",
    "        out2 = model.forward(input_ids_2, attention_mask_2)\n",
    "        diff = (out1 - out2).squeeze()\n",
    "        diff = torch.sigmoid(diff).to(device)\n",
    "        loss = loss_fn(diff, y.float().to(device))\n",
    "        \n",
    "        for i in range(len(diff)):\n",
    "            if (diff[i] >= 0.5 and y[i] == 1) or (diff[i] < 0.5 and y[i] == 0):\n",
    "                acc_tp_tn += 1\n",
    "            acc_total +=1\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    logger.info(\"[%d] train loss: %.10f\" % (epoch + 1, train_loss / len(dataloader)))\n",
    "    logging.info(\"[%d] train accuracy: %.10f\" % (epoch + 1, acc_tp_tn / acc_total))\n",
    "\n",
    "    if saving:\n",
    "        path = './outputs/model_' + str(epoch+1) + '.pth'\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "        }, path)\n",
    "        logger.info(\"Model saved..\")\n",
    "\n",
    "    if tune:\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((model.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "    logger.info(\"Training finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "V4-vkMnZ8cq7"
   },
   "outputs": [],
   "source": [
    "def val(model, loss_fn, dataloader, epoch, tune=False):\n",
    "        val_loss = 0.0\n",
    "        acc_tp_tn = 0\n",
    "        acc_total = 0\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        for X, y in dataloader:\n",
    "            with torch.no_grad():\n",
    "                input_ids_1 = X[0]['input_ids'].squeeze().to(device)\n",
    "                attention_mask_1 = X[0]['attention_mask'].squeeze().to(device)\n",
    "                input_ids_2 = X[1]['input_ids'].squeeze().to(device)\n",
    "                attention_mask_2 = X[1]['attention_mask'].squeeze().to(device)\n",
    "                out1 = model.forward(input_ids_1, attention_mask_1)\n",
    "                out2 = model.forward(input_ids_2, attention_mask_2)\n",
    "                diff = (out1 - out2).squeeze()\n",
    "                diff = torch.sigmoid(diff)\n",
    "                loss = loss_fn(diff, y.float().to(device))\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                \n",
    "                for i in range(len(diff)):\n",
    "                    if (diff[i] >= 0.5 and y[i] == 1) or (diff[i] < 0.5 and y[i] == 0):\n",
    "                        acc_tp_tn += 1\n",
    "                    acc_total +=1\n",
    "\n",
    "        if(tune):\n",
    "            tune.report(loss=val_loss)\n",
    "\n",
    "        logger.info(\"[%d] val loss: %.10f\" % (epoch+1, val_loss/len(dataloader)))\n",
    "        logging.info(\"[%d] val acc: %.10f\" % (epoch + 1, acc_tp_tn/acc_total))\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PEGxtzDEPLDQ"
   },
   "outputs": [],
   "source": [
    "def train_tune(config, data_dir=\"./data\"):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = ProductRanker(config[\"l1\"],config[\"l2\"]).to(device)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"], betas=(0.9, 0.999), eps=1e-08, weight_decay=0,\n",
    "                                amsgrad=False)\n",
    "    \n",
    "    train_set, val_set = dataPreparation(data_dir)\n",
    "    dataloader_train = createDataloader(train_set, config)\n",
    "    dataloader_val = createDataloader(val_set, config)\n",
    "\n",
    "    train(model, optimizer, dataloader_train, 0, tune=True)\n",
    "    val(model, loss_fn, dataloader_val, 0, tune=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3mrEAanp9OFO"
   },
   "outputs": [],
   "source": [
    "def tune_hyperparameters():\n",
    "    data_dir = os.path.abspath(\"./data\")\n",
    "    config = {\n",
    "        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
    "        \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"batch_size\": tune.choice([2, 4, 8, 16])\n",
    "    }\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=4,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    reporter = CLIReporter(\n",
    "        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n",
    "        metric_columns=[\"loss\", \"training_iteration\"])\n",
    "    result = tune.run(\n",
    "        partial(train_tune, data_dir=data_dir),\n",
    "        resources_per_trial={\"cpu\": 12, \"gpu\": 1},\n",
    "        config=config,\n",
    "        num_samples=10,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "YStntQVRDUGM"
   },
   "outputs": [],
   "source": [
    "def tune_lr():\n",
    "    data_dir = os.path.abspath(\"./data\")\n",
    "    config = {\n",
    "        'l1': 256,\n",
    "        'l2': 8,\n",
    "        'lr': tune.loguniform(1e-4, 1e-1),\n",
    "        'batch_size': 4}\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=5,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    reporter = CLIReporter(\n",
    "        metric_columns=[\"loss\", \"training_iteration\"])\n",
    "    result = tune.run(\n",
    "        partial(train_tune, data_dir=data_dir),\n",
    "        resources_per_trial={\"cpu\": 12, \"gpu\": 1},\n",
    "        local_dir=\"./ray_results\",\n",
    "        config=config,\n",
    "        num_samples=5,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    best_checkpoint = result.get_best_checkpoint(best_trial, metric=\"loss\", mode=\"min\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "NmPbsO6w9c7T"
   },
   "outputs": [],
   "source": [
    "def train_model(epochs, config, from_checkpoint=False, path=None):\n",
    "    data_dir = os.path.abspath(\"./data\")\n",
    "    train(epochs, config, data_dir, from_checkpoint, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataloader):    \n",
    "    return_ranks = {}\n",
    "    number_of_batches = 0\n",
    "    for X, y in dataloader:\n",
    "        with torch.no_grad():\n",
    "            input_ids = X[0]['input_ids'].squeeze().to(device)\n",
    "            attention_mask = X[0]['attention_mask'].squeeze().to(device)\n",
    "            out = model.forward(input_ids, attention_mask).squeeze().cpu().numpy()\n",
    "            for i, result in enumerate(out):\n",
    "                return_ranks[i+number_of_batches*100] = result       \n",
    "        number_of_batches += 1       \n",
    "\n",
    "    return {key: rank for rank, key in enumerate(sorted(return_ranks, key=return_ranks.get, reverse=True), 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "rQ6Va6c59fP1"
   },
   "outputs": [],
   "source": [
    "def training_loop(epochs, train_bool=True, validate_bool=True, data_dir=\"./data\", saving=False, load=False):\n",
    "    getJSON()\n",
    "    train_set, val_set = dataPreparation()\n",
    "    dataloader_train = createDataloader(train_set, config)\n",
    "    dataloader_val = createDataloader(val_set, config)\n",
    "    \n",
    "    if train_bool or validate_bool:\n",
    "        for epoch in range(epochs):\n",
    "            if load:\n",
    "                current_model_filename = './outputs/model_' + str(epoch+1) + '.pth'\n",
    "                if os.path.exists(current_model_filename):\n",
    "                        checkpoint = torch.load(current_model_filename)\n",
    "                        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                else:\n",
    "                    logger.info(f\"model: {current_model_filename} doesnt exist\")\n",
    "\n",
    "            logger.info(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "            if train_bool:\n",
    "                logger.info(\"Starting training loop...\")\n",
    "                train(model, loss_fn, optimizer, dataloader_train, epoch, saving=saving, tune=False)\n",
    "\n",
    "            if validate_bool:\n",
    "                logger.info(\"Starting validation loop...\")\n",
    "                val(model, loss_fn, dataloader_val, epoch, tune=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C7vVclae-Ze6",
    "outputId": "8e959e24-d0a5-44e9-d177-ade3880bf22c"
   },
   "outputs": [],
   "source": [
    "#training_loop(5, train_bool=False, validate_bool=False, saving=False, load=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new HTTPS connection (1): huggingface.co:443\n",
      "https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3801: 1, 385: 2, 3788: 3, 1369: 4, 624: 5, 210: 6, 3168: 7, 2301: 8, 1338: 9, 5074: 10, 3157: 11, 4691: 12, 2887: 13, 3096: 14, 3328: 15, 1880: 16, 3662: 17, 5567: 18, 2021: 19, 1408: 20, 4708: 21, 1593: 22, 2140: 23, 2673: 24, 4845: 25, 4041: 26, 1097: 27, 4346: 28, 1244: 29, 3564: 30, 4734: 31, 486: 32, 1989: 33, 3365: 34, 699: 35, 4851: 36, 806: 37, 1889: 38, 2237: 39, 1677: 40, 3283: 41, 4344: 42, 3016: 43, 4370: 44, 962: 45, 5132: 46, 2997: 47, 4076: 48, 2478: 49, 1563: 50, 1016: 51, 5372: 52, 1822: 53, 928: 54, 4644: 55, 4854: 56, 3098: 57, 2207: 58, 5389: 59, 5271: 60, 577: 61, 1413: 62, 44: 63, 1141: 64, 3920: 65, 5165: 66, 1877: 67, 5078: 68, 4175: 69, 3561: 70, 2956: 71, 104: 72, 146: 73, 3571: 74, 328: 75, 990: 76, 662: 77, 1770: 78, 1836: 79, 2460: 80, 2644: 81, 5098: 82, 1143: 83, 2398: 84, 739: 85, 3177: 86, 2059: 87, 1733: 88, 1477: 89, 1156: 90, 5265: 91, 863: 92, 2647: 93, 365: 94, 2181: 95, 5232: 96, 259: 97, 53: 98, 2020: 99, 2901: 100, 243: 101, 1555: 102, 1109: 103, 1991: 104, 3425: 105, 3312: 106, 803: 107, 3001: 108, 4373: 109, 1434: 110, 2422: 111, 3687: 112, 1241: 113, 4186: 114, 2159: 115, 3499: 116, 3624: 117, 3773: 118, 4260: 119, 763: 120, 3357: 121, 1340: 122, 4729: 123, 974: 124, 2874: 125, 4150: 126, 5225: 127, 3952: 128, 4275: 129, 2385: 130, 5095: 131, 2458: 132, 4059: 133, 4687: 134, 5316: 135, 5551: 136, 2891: 137, 3809: 138, 5550: 139, 4070: 140, 3708: 141, 4756: 142, 3651: 143, 430: 144, 160: 145, 4075: 146, 3250: 147, 4282: 148, 3261: 149, 1741: 150, 5018: 151, 805: 152, 2139: 153, 3961: 154, 2006: 155, 345: 156, 4381: 157, 5507: 158, 1457: 159, 994: 160, 869: 161, 2217: 162, 1614: 163, 2564: 164, 4493: 165, 5596: 166, 187: 167, 3888: 168, 4569: 169, 3405: 170, 4369: 171, 5377: 172, 3286: 173, 1768: 174, 1253: 175, 2983: 176, 2279: 177, 3340: 178, 1189: 179, 1952: 180, 2033: 181, 1634: 182, 3301: 183, 3813: 184, 4110: 185, 4967: 186, 4312: 187, 1485: 188, 3666: 189, 3150: 190, 1299: 191, 2107: 192, 2657: 193, 908: 194, 4732: 195, 1885: 196, 2546: 197, 2131: 198, 5487: 199, 5140: 200, 5528: 201, 3885: 202, 4376: 203, 2550: 204, 3285: 205, 777: 206, 4878: 207, 3900: 208, 1810: 209, 4087: 210, 2170: 211, 4893: 212, 5475: 213, 2288: 214, 1383: 215, 4039: 216, 2597: 217, 1183: 218, 1892: 219, 1482: 220, 2479: 221, 5517: 222, 3720: 223, 3521: 224, 2861: 225, 3963: 226, 5585: 227, 3482: 228, 5472: 229, 2595: 230, 4204: 231, 722: 232, 4916: 233, 4444: 234, 1883: 235, 439: 236, 2911: 237, 3241: 238, 3560: 239, 1782: 240, 2318: 241, 4882: 242, 3756: 243, 1019: 244, 1231: 245, 1887: 246, 4943: 247, 4515: 248, 1251: 249, 2691: 250, 5308: 251, 5237: 252, 5120: 253, 1626: 254, 4296: 255, 4618: 256, 4946: 257, 2014: 258, 2680: 259, 4229: 260, 3537: 261, 4974: 262, 562: 263, 2808: 264, 5268: 265, 4134: 266, 3869: 267, 1866: 268, 754: 269, 2759: 270, 1906: 271, 1925: 272, 2845: 273, 2247: 274, 4639: 275, 4944: 276, 4568: 277, 4655: 278, 780: 279, 5105: 280, 514: 281, 1716: 282, 1308: 283, 3802: 284, 1651: 285, 1961: 286, 4244: 287, 1462: 288, 674: 289, 1489: 290, 415: 291, 1986: 292, 2425: 293, 111: 294, 2052: 295, 2924: 296, 331: 297, 5179: 298, 2915: 299, 3928: 300, 4897: 301, 5441: 302, 4755: 303, 2193: 304, 4683: 305, 2675: 306, 5103: 307, 1438: 308, 4852: 309, 2211: 310, 282: 311, 2957: 312, 4459: 313, 5243: 314, 1349: 315, 3887: 316, 3025: 317, 2397: 318, 3787: 319, 938: 320, 3151: 321, 5197: 322, 1840: 323, 5380: 324, 3658: 325, 2121: 326, 4988: 327, 1182: 328, 3101: 329, 2883: 330, 2559: 331, 1184: 332, 3496: 333, 1549: 334, 348: 335, 3369: 336, 2175: 337, 5157: 338, 3314: 339, 608: 340, 1516: 341, 3229: 342, 2908: 343, 1771: 344, 1852: 345, 2457: 346, 3709: 347, 4362: 348, 2333: 349, 2936: 350, 3086: 351, 557: 352, 4120: 353, 4283: 354, 4785: 355, 2549: 356, 460: 357, 280: 358, 1640: 359, 2630: 360, 5193: 361, 4526: 362, 1938: 363, 3431: 364, 2245: 365, 1987: 366, 992: 367, 611: 368, 283: 369, 3752: 370, 4783: 371, 2296: 372, 2095: 373, 344: 374, 2029: 375, 2967: 376, 1826: 377, 2191: 378, 4947: 379, 3027: 380, 3087: 381, 4033: 382, 1283: 383, 4141: 384, 2275: 385, 1155: 386, 3711: 387, 4249: 388, 4095: 389, 2641: 390, 2667: 391, 391: 392, 2090: 393, 3187: 394, 2224: 395, 3692: 396, 2587: 397, 4396: 398, 1794: 399, 5050: 400, 1526: 401, 3303: 402, 5000: 403, 1805: 404, 3583: 405, 5457: 406, 943: 407, 4941: 408, 1940: 409, 4479: 410, 1454: 411, 4166: 412, 1684: 413, 2856: 414, 3861: 415, 5147: 416, 3573: 417, 5062: 418, 3420: 419, 3057: 420, 120: 421, 1984: 422, 3089: 423, 5310: 424, 676: 425, 1322: 426, 4319: 427, 3099: 428, 1953: 429, 4318: 430, 1799: 431, 2993: 432, 677: 433, 5474: 434, 1900: 435, 3857: 436, 1009: 437, 2384: 438, 420: 439, 3004: 440, 2031: 441, 5329: 442, 5463: 443, 1773: 444, 2503: 445, 4189: 446, 728: 447, 3066: 448, 3451: 449, 5273: 450, 5414: 451, 2629: 452, 2394: 453, 3943: 454, 1293: 455, 983: 456, 5439: 457, 4269: 458, 2572: 459, 5536: 460, 2687: 461, 1617: 462, 5142: 463, 3504: 464, 18: 465, 3726: 466, 2797: 467, 1124: 468, 3893: 469, 2803: 470, 1407: 471, 684: 472, 766: 473, 3944: 474, 90: 475, 1610: 476, 3986: 477, 835: 478, 2415: 479, 1403: 480, 2362: 481, 4064: 482, 1916: 483, 4356: 484, 4010: 485, 2339: 486, 1833: 487, 2182: 488, 4548: 489, 3393: 490, 3626: 491, 510: 492, 4065: 493, 4146: 494, 4063: 495, 2469: 496, 5251: 497, 183: 498, 342: 499, 140: 500, 2046: 501, 1316: 502, 1812: 503, 225: 504, 1824: 505, 3938: 506, 2935: 507, 1718: 508, 5196: 509, 4455: 510, 3528: 511, 117: 512, 416: 513, 4239: 514, 2662: 515, 1663: 516, 5602: 517, 505: 518, 4404: 519, 2694: 520, 626: 521, 613: 522, 2294: 523, 4142: 524, 2360: 525, 4676: 526, 4993: 527, 2338: 528, 1202: 529, 2141: 530, 3713: 531, 2013: 532, 2040: 533, 4930: 534, 5575: 535, 2501: 536, 3341: 537, 5143: 538, 3738: 539, 2214: 540, 5166: 541, 4001: 542, 5416: 543, 1348: 544, 2752: 545, 3745: 546, 257: 547, 3203: 548, 4224: 549, 2094: 550, 3698: 551, 394: 552, 130: 553, 2223: 554, 4421: 555, 206: 556, 985: 557, 5473: 558, 5478: 559, 4458: 560, 3243: 561, 1937: 562, 4556: 563, 3124: 564, 1710: 565, 4461: 566, 103: 567, 802: 568, 4053: 569, 3291: 570, 998: 571, 5263: 572, 817: 573, 2346: 574, 4979: 575, 4138: 576, 1279: 577, 4695: 578, 5153: 579, 3332: 580, 4199: 581, 2796: 582, 930: 583, 1272: 584, 606: 585, 1881: 586, 1948: 587, 2041: 588, 3960: 589, 4340: 590, 1398: 591, 2941: 592, 1965: 593, 1996: 594, 2763: 595, 2168: 596, 3306: 597, 4876: 598, 886: 599, 3390: 600, 3122: 601, 3074: 602, 1065: 603, 1029: 604, 1488: 605, 4718: 606, 1061: 607, 3958: 608, 2236: 609, 4894: 610, 2472: 611, 1064: 612, 4055: 613, 4496: 614, 2204: 615, 5318: 616, 2446: 617, 1031: 618, 4177: 619, 1444: 620, 72: 621, 507: 622, 4788: 623, 4161: 624, 4585: 625, 643: 626, 5532: 627, 1981: 628, 318: 629, 2972: 630, 3655: 631, 1230: 632, 457: 633, 5582: 634, 4543: 635, 5607: 636, 1440: 637, 4507: 638, 2671: 639, 1452: 640, 3828: 641, 3503: 642, 5426: 643, 454: 644, 2400: 645, 5365: 646, 1513: 647, 5281: 648, 1657: 649, 2104: 650, 119: 651, 3080: 652, 3993: 653, 3495: 654, 1059: 655, 498: 656, 5300: 657, 2853: 658, 911: 659, 4631: 660, 4435: 661, 301: 662, 5087: 663, 0: 664, 4594: 665, 2966: 666, 1778: 667, 292: 668, 4250: 669, 4000: 670, 1018: 671, 5611: 672, 2885: 673, 2297: 674, 1232: 675, 3739: 676, 1123: 677, 4330: 678, 2622: 679, 4673: 680, 3805: 681, 5292: 682, 2468: 683, 252: 684, 3559: 685, 4972: 686, 3853: 687, 3300: 688, 4994: 689, 2413: 690, 3038: 691, 2625: 692, 4040: 693, 1627: 694, 4328: 695, 1020: 696, 5064: 697, 4546: 698, 2315: 699, 3164: 700, 1052: 701, 3210: 702, 121: 703, 5186: 704, 4206: 705, 2008: 706, 2239: 707, 2030: 708, 5220: 709, 1766: 710, 3411: 711, 5230: 712, 2782: 713, 2238: 714, 2781: 715, 4429: 716, 1175: 717, 3436: 718, 3264: 719, 4129: 720, 217: 721, 2753: 722, 5159: 723, 3937: 724, 2451: 725, 1569: 726, 840: 727, 4726: 728, 3569: 729, 5135: 730, 4181: 731, 4573: 732, 3394: 733, 4168: 734, 3280: 735, 2395: 736, 4575: 737, 1048: 738, 2354: 739, 4268: 740, 4197: 741, 3354: 742, 2064: 743, 3546: 744, 661: 745, 446: 746, 2347: 747, 5455: 748, 4902: 749, 386: 750, 3818: 751, 4647: 752, 5111: 753, 5549: 754, 1800: 755, 5245: 756, 4333: 757, 5521: 758, 3875: 759, 3200: 760, 705: 761, 4510: 762, 4696: 763, 537: 764, 5227: 765, 4522: 766, 4577: 767, 5374: 768, 4476: 769, 1481: 770, 4567: 771, 1576: 772, 1562: 773, 4345: 774, 1328: 775, 5053: 776, 3045: 777, 3468: 778, 5002: 779, 151: 780, 3665: 781, 2523: 782, 3530: 783, 5618: 784, 2309: 785, 5218: 786, 2471: 787, 1060: 788, 2001: 789, 4131: 790, 3815: 791, 854: 792, 4169: 793, 2148: 794, 1351: 795, 4511: 796, 3604: 797, 2617: 798, 5313: 799, 2872: 800, 1066: 801, 870: 802, 3531: 803, 4407: 804, 4634: 805, 4826: 806, 1137: 807, 2731: 808, 4505: 809, 4664: 810, 2526: 811, 667: 812, 3068: 813, 4850: 814, 2203: 815, 1412: 816, 1606: 817, 1222: 818, 3678: 819, 2703: 820, 2922: 821, 730: 822, 2704: 823, 1831: 824, 1725: 825, 4917: 826, 830: 827, 4648: 828, 312: 829, 3418: 830, 1554: 831, 203: 832, 1274: 833, 2115: 834, 4474: 835, 1032: 836, 1159: 837, 4910: 838, 1103: 839, 5459: 840, 4211: 841, 3128: 842, 4497: 843, 1101: 844, 2304: 845, 2329: 846, 3858: 847, 5081: 848, 2640: 849, 4764: 850, 2516: 851, 4760: 852, 2045: 853, 5520: 854, 3742: 855, 2374: 856, 4864: 857, 1352: 858, 3277: 859, 2009: 860, 3209: 861, 2100: 862, 5003: 863, 3781: 864, 2642: 865, 4482: 866, 1366: 867, 1801: 868, 4844: 869, 3532: 870, 570: 871, 820: 872, 5588: 873, 1547: 874, 3182: 875, 3320: 876, 5603: 877, 5466: 878, 3949: 879, 2103: 880, 960: 881, 5510: 882, 2257: 883, 4913: 884, 2807: 885, 4799: 886, 1320: 887, 2379: 888, 2556: 889, 4798: 890, 695: 891, 1335: 892, 3552: 893, 1837: 894, 5399: 895, 532: 896, 3064: 897, 2793: 898, 3116: 899, 3549: 900, 1647: 901, 93: 902, 4274: 903, 1034: 904, 3941: 905, 944: 906, 2201: 907, 1956: 908, 204: 909, 4014: 910, 4443: 911, 3323: 912, 2620: 913, 3912: 914, 2027: 915, 2603: 916, 689: 917, 1643: 918, 2369: 919, 2359: 920, 548: 921, 1867: 922, 4816: 923, 5141: 924, 2906: 925, 5595: 926, 3223: 927, 28: 928, 4137: 929, 5194: 930, 3732: 931, 4706: 932, 170: 933, 4892: 934, 1045: 935, 3942: 936, 3462: 937, 233: 938, 157: 939, 1623: 940, 2615: 941, 2265: 942, 2513: 943, 4591: 944, 4263: 945, 1147: 946, 4259: 947, 1491: 948, 4124: 949, 1698: 950, 2199: 951, 3930: 952, 5341: 953, 4449: 954, 25: 955, 1001: 956, 4382: 957, 1309: 958, 2407: 959, 2113: 960, 731: 961, 4963: 962, 4571: 963, 449: 964, 2578: 965, 5468: 966, 3859: 967, 2600: 968, 3842: 969, 2989: 970, 1401: 971, 5491: 972, 1579: 973, 3484: 974, 1171: 975, 1703: 976, 3007: 977, 3020: 978, 5339: 979, 644: 980, 4441: 981, 1532: 982, 3185: 983, 2345: 984, 1994: 985, 397: 986, 948: 987, 1354: 988, 2814: 989, 3100: 990, 3906: 991, 619: 992, 1234: 993, 62: 994, 808: 995, 2863: 996, 2830: 997, 2847: 998, 4668: 999, 3836: 1000, 4880: 1001, 3166: 1002, 873: 1003, 3868: 1004, 2475: 1005, 525: 1006, 4398: 1007, 2735: 1008, 1621: 1009, 5168: 1010, 5325: 1011, 597: 1012, 4879: 1013, 784: 1014, 4099: 1015, 3386: 1016, 4203: 1017, 1154: 1018, 1918: 1019, 850: 1020, 5402: 1021, 2044: 1022, 827: 1023, 2449: 1024, 1374: 1025, 801: 1026, 2185: 1027, 2146: 1028, 1966: 1029, 2240: 1030, 1292: 1031, 1030: 1032, 215: 1033, 2738: 1034, 5571: 1035, 1043: 1036, 2135: 1037, 4643: 1038, 4397: 1039, 2900: 1040, 423: 1041, 1654: 1042, 2739: 1043, 3081: 1044, 906: 1045, 1000: 1046, 1468: 1047, 2554: 1048, 4172: 1049, 3134: 1050, 5621: 1051, 3453: 1052, 71: 1053, 524: 1054, 5523: 1055, 3117: 1056, 78: 1057, 4154: 1058, 4975: 1059, 2679: 1060, 890: 1061, 987: 1062, 1484: 1063, 2128: 1064, 4298: 1065, 2430: 1066, 4047: 1067, 223: 1068, 3076: 1069, 1365: 1070, 3539: 1071, 1538: 1072, 5535: 1073, 1628: 1074, 2886: 1075, 4473: 1076, 3048: 1077, 1854: 1078, 1680: 1079, 4179: 1080, 3097: 1081, 1788: 1082, 4561: 1083, 2557: 1084, 1259: 1085, 1655: 1086, 2696: 1087, 5244: 1088, 2766: 1089, 1237: 1090, 4303: 1091, 3438: 1092, 4989: 1093, 4489: 1094, 399: 1095, 5546: 1096, 2280: 1097, 4293: 1098, 1451: 1099, 2233: 1100, 680: 1101, 2689: 1102, 459: 1103, 1121: 1104, 582: 1105, 1013: 1106, 1671: 1107, 3132: 1108, 4074: 1109, 5357: 1110, 3722: 1111, 975: 1112, 2870: 1113, 5427: 1114, 601: 1115, 4117: 1116, 4357: 1117, 4563: 1118, 1920: 1119, 1092: 1120, 2492: 1121, 4046: 1122, 82: 1123, 3471: 1124, 5529: 1125, 5149: 1126, 3204: 1127, 4521: 1128, 4262: 1129, 1522: 1130, 846: 1131, 4762: 1132, 3342: 1133, 4054: 1134, 4377: 1135, 4991: 1136, 3976: 1137, 4107: 1138, 3142: 1139, 2962: 1140, 751: 1141, 1853: 1142, 3939: 1143, 4748: 1144, 3454: 1145, 2371: 1146, 4532: 1147, 2730: 1148, 2655: 1149, 4817: 1150, 5277: 1151, 1570: 1152, 3855: 1153, 4766: 1154, 1845: 1155, 2505: 1156, 2219: 1157, 1095: 1158, 427: 1159, 4981: 1160, 465: 1161, 2925: 1162, 1742: 1163, 3572: 1164, 419: 1165, 2421: 1166, 4837: 1167, 3974: 1168, 1888: 1169, 1839: 1170, 3445: 1171, 5336: 1172, 421: 1173, 2919: 1174, 1275: 1175, 5192: 1176, 3661: 1177, 2928: 1178, 4209: 1179, 3133: 1180, 5025: 1181, 733: 1182, 4472: 1183, 2939: 1184, 3037: 1185, 4390: 1186, 949: 1187, 774: 1188, 1922: 1189, 150: 1190, 455: 1191, 3580: 1192, 4578: 1193, 2380: 1194, 2195: 1195, 3608: 1196, 4286: 1197, 5513: 1198, 1172: 1199, 2736: 1200, 1472: 1201, 3761: 1202, 154: 1203, 719: 1204, 2163: 1205, 768: 1206, 1128: 1207, 3433: 1208, 3535: 1209, 2713: 1210, 3992: 1211, 3050: 1212, 3750: 1213, 4006: 1214, 5275: 1215, 310: 1216, 1360: 1217, 723: 1218, 177: 1219, 2102: 1220, 4640: 1221, 5185: 1222, 4616: 1223, 3896: 1224, 3775: 1225, 4812: 1226, 2213: 1227, 2917: 1228, 1529: 1229, 293: 1230, 4432: 1231, 1728: 1232, 1624: 1233, 4698: 1234, 4291: 1235, 2396: 1236, 3676: 1237, 354: 1238, 1461: 1239, 3415: 1240, 815: 1241, 833: 1242, 2827: 1243, 1076: 1244, 2725: 1245, 1518: 1246, 4152: 1247, 3302: 1248, 715: 1249, 3743: 1250, 2088: 1251, 4044: 1252, 2215: 1253, 2734: 1254, 4078: 1255, 4922: 1256, 5009: 1257, 14: 1258, 3872: 1259, 2519: 1260, 3404: 1261, 3553: 1262, 2405: 1263, 3817: 1264, 4430: 1265, 4321: 1266, 925: 1267, 181: 1268, 1357: 1269, 3102: 1270, 266: 1271, 3012: 1272, 5266: 1273, 1381: 1274, 467: 1275, 3385: 1276, 2114: 1277, 2016: 1278, 1269: 1279, 3222: 1280, 1652: 1281, 1193: 1282, 651: 1283, 650: 1284, 5388: 1285, 838: 1286, 2591: 1287, 2187: 1288, 1165: 1289, 3194: 1290, 133: 1291, 245: 1292, 2686: 1293, 5298: 1294, 10: 1295, 4820: 1296, 4588: 1297, 1216: 1298, 4173: 1299, 2720: 1300, 5438: 1301, 762: 1302, 513: 1303, 171: 1304, 671: 1305, 1638: 1306, 811: 1307, 924: 1308, 905: 1309, 1314: 1310, 3685: 1311, 3041: 1312, 3816: 1313, 3894: 1314, 5366: 1315, 2561: 1316, 30: 1317, 713: 1318, 2794: 1319, 1498: 1320, 4158: 1321, 3483: 1322, 77: 1323, 3911: 1324, 3636: 1325, 410: 1326, 3990: 1327, 2895: 1328, 4612: 1329, 3697: 1330, 1344: 1331, 5437: 1332, 1422: 1333, 3618: 1334, 4270: 1335, 5180: 1336, 637: 1337, 5502: 1338, 2819: 1339, 2072: 1340, 2081: 1341, 5107: 1342, 2331: 1343, 3121: 1344, 3652: 1345, 5022: 1346, 5083: 1347, 5033: 1348, 4360: 1349, 3461: 1350, 4662: 1351, 1670: 1352, 479: 1353, 1041: 1354, 408: 1355, 1814: 1356, 3305: 1357, 2348: 1358, 175: 1359, 887: 1360, 3307: 1361, 2825: 1362, 2582: 1363, 4256: 1364, 125: 1365, 4335: 1366, 2324: 1367, 3211: 1368, 4998: 1369, 1377: 1370, 2985: 1371, 3434: 1372, 1185: 1373, 5580: 1374, 1894: 1375, 1022: 1376, 248: 1377, 2876: 1378, 1545: 1379, 1864: 1380, 1544: 1381, 1337: 1382, 264: 1383, 472: 1384, 59: 1385, 4251: 1386, 2636: 1387, 4992: 1388, 3108: 1389, 2327: 1390, 1044: 1391, 5382: 1392, 4410: 1393, 898: 1394, 3225: 1395, 3779: 1396, 4323: 1397, 5226: 1398, 390: 1399, 1082: 1400, 3806: 1401, 3590: 1402, 471: 1403, 3192: 1404, 414: 1405, 4248: 1406, 2855: 1407, 660: 1408, 3075: 1409, 1830: 1410, 100: 1411, 4908: 1412, 3318: 1413, 3313: 1414, 3987: 1415, 3776: 1416, 1999: 1417, 5519: 1418, 5424: 1419, 4347: 1420, 3419: 1421, 5035: 1422, 5167: 1423, 5214: 1424, 1681: 1425, 4602: 1426, 4400: 1427, 5276: 1428, 958: 1429, 4145: 1430, 2225: 1431, 300: 1432, 281: 1433, 4656: 1434, 3688: 1435, 1117: 1436, 2953: 1437, 1993: 1438, 4052: 1439, 4300: 1440, 1636: 1441, 254: 1442, 864: 1443, 1446: 1444, 3227: 1445, 3753: 1446, 3905: 1447, 3439: 1448, 3381: 1449, 3837: 1450, 1475: 1451, 2028: 1452, 2719: 1453, 5340: 1454, 3511: 1455, 4302: 1456, 2125: 1457, 4936: 1458, 589: 1459, 2096: 1460, 895: 1461, 2473: 1462, 5410: 1463, 2942: 1464, 3972: 1465, 4394: 1466, 1445: 1467, 36: 1468, 3024: 1469, 3172: 1470, 3620: 1471, 675: 1472, 4469: 1473, 3595: 1474, 3669: 1475, 2221: 1476, 3408: 1477, 49: 1478, 3008: 1479, 145: 1480, 241: 1481, 4621: 1482, 1898: 1483, 5617: 1484, 4237: 1485, 2093: 1486, 913: 1487, 1399: 1488, 1375: 1489, 2779: 1490, 4956: 1491, 3380: 1492, 4809: 1493, 2156: 1494, 5200: 1495, 238: 1496, 1842: 1497, 2521: 1498, 2097: 1499, 3207: 1500, 3084: 1501, 3378: 1502, 3668: 1503, 4923: 1504, 443: 1505, 868: 1506, 5109: 1507, 314: 1508, 1931: 1509, 2678: 1510, 533: 1511, 1089: 1512, 3871: 1513, 166: 1514, 1364: 1515, 2849: 1516, 3619: 1517, 584: 1518, 5564: 1519, 86: 1520, 176: 1521, 1295: 1522, 4815: 1523, 4338: 1524, 3625: 1525, 1924: 1526, 4324: 1527, 4978: 1528, 85: 1529, 2910: 1530, 3260: 1531, 5210: 1532, 2996: 1533, 5305: 1534, 5201: 1535, 1494: 1536, 5443: 1537, 3778: 1538, 4782: 1539, 2433: 1540, 2658: 1541, 692: 1542, 2391: 1543, 4761: 1544, 4862: 1545, 2276: 1546, 3679: 1547, 3520: 1548, 440: 1549, 4527: 1550, 2865: 1551, 322: 1552, 1483: 1553, 4077: 1554, 3970: 1555, 1492: 1556, 3598: 1557, 3946: 1558, 5425: 1559, 1210: 1560, 4680: 1561, 822: 1562, 2311: 1563, 2932: 1564, 1641: 1565, 4859: 1566, 5612: 1567, 3649: 1568, 4953: 1569, 1536: 1570, 3153: 1571, 2580: 1572, 5350: 1573, 3052: 1574, 4098: 1575, 350: 1576, 1500: 1577, 294: 1578, 3362: 1579, 5576: 1580, 855: 1581, 3249: 1582, 2218: 1583, 5362: 1584, 1271: 1585, 3923: 1586, 3143: 1587, 1359: 1588, 5181: 1589, 804: 1590, 3830: 1591, 2631: 1592, 3862: 1593, 1586: 1594, 1754: 1595, 5115: 1596, 3599: 1597, 5133: 1598, 2890: 1599, 5370: 1600, 29: 1601, 3529: 1602, 3834: 1603, 3642: 1604, 3904: 1605, 3623: 1606, 4774: 1607, 2393: 1608, 65: 1609, 3123: 1610, 3176: 1611, 4786: 1612, 4784: 1613, 1508: 1614, 4971: 1615, 3820: 1616, 2693: 1617, 1227: 1618, 4018: 1619, 3224: 1620, 583: 1621, 3366: 1622, 4650: 1623, 2079: 1624, 5460: 1625, 1786: 1626, 1157: 1627, 3811: 1628, 1588: 1629, 2633: 1630, 4038: 1631, 1490: 1632, 2335: 1633, 3594: 1634, 844: 1635, 319: 1636, 3670: 1637, 4829: 1638, 4846: 1639, 4261: 1640, 1419: 1641, 794: 1642, 5282: 1643, 3262: 1644, 1988: 1645, 3030: 1646, 741: 1647, 1891: 1648, 2660: 1649, 5525: 1650, 3562: 1651, 594: 1652, 622: 1653, 4280: 1654, 5335: 1655, 4465: 1656, 2485: 1657, 4122: 1658, 4790: 1659, 1153: 1660, 70: 1661, 2896: 1662, 4722: 1663, 1873: 1664, 4514: 1665, 3193: 1666, 5401: 1667, 2005: 1668, 697: 1669, 4220: 1670, 4072: 1671, 278: 1672, 2812: 1673, 2186: 1674, 3518: 1675, 1206: 1676, 4711: 1677, 2747: 1678, 1862: 1679, 4452: 1680, 3786: 1681, 3367: 1682, 2438: 1683, 3936: 1684, 539: 1685, 3065: 1686, 451: 1687, 4257: 1688, 2649: 1689, 857: 1690, 1860: 1691, 1178: 1692, 1268: 1693, 267: 1694, 114: 1695, 691: 1696, 1134: 1697, 2994: 1698, 3796: 1699, 432: 1700, 4487: 1701, 1573: 1702, 3343: 1703, 1368: 1704, 8: 1705, 2091: 1706, 2815: 1707, 290: 1708, 1057: 1709, 1600: 1710, 2628: 1711, 5479: 1712, 2721: 1713, 3589: 1714, 3022: 1715, 5254: 1716, 787: 1717, 2920: 1718, 848: 1719, 284: 1720, 3473: 1721, 3292: 1722, 98: 1723, 1732: 1724, 4503: 1725, 2056: 1726, 5294: 1727, 2921: 1728, 5444: 1729, 2757: 1730, 785: 1731, 646: 1732, 1897: 1733, 4626: 1734, 4073: 1735, 5058: 1736, 3948: 1737, 3774: 1738, 1190: 1739, 2160: 1740, 4736: 1741, 5431: 1742, 1507: 1743, 3748: 1744, 124: 1745, 1219: 1746, 2999: 1747, 2465: 1748, 2268: 1749, 1678: 1750, 4921: 1751, 2487: 1752, 3322: 1753, 670: 1754, 4306: 1755, 797: 1756, 2179: 1757, 3359: 1758, 4608: 1759, 3707: 1760, 1473: 1761, 819: 1762, 1011: 1763, 1502: 1764, 4980: 1765, 760: 1766, 5534: 1767, 4508: 1768, 4973: 1769, 1008: 1770, 299: 1771, 1447: 1772, 1775: 1773, 323: 1774, 3647: 1775, 4891: 1776, 1857: 1777, 3034: 1778, 5494: 1779, 1691: 1780, 896: 1781, 3154: 1782, 2459: 1783, 1273: 1784, 4730: 1785, 1037: 1786, 1186: 1787, 4424: 1788, 1050: 1789, 5145: 1790, 566: 1791, 1543: 1792, 3579: 1793, 4183: 1794, 4484: 1795, 5337: 1796, 5010: 1797, 2500: 1798, 897: 1799, 5620: 1800, 2282: 1801, 1578: 1802, 400: 1803, 1553: 1804, 1802: 1805, 2144: 1806, 2862: 1807, 1780: 1808, 921: 1809, 2589: 1810, 3296: 1811, 2124: 1812, 3841: 1813, 3437: 1814, 3395: 1815, 5283: 1816, 4551: 1817, 2464: 1818, 3136: 1819, 1173: 1820, 4504: 1821, 435: 1822, 5052: 1823, 216: 1824, 1534: 1825, 5591: 1826, 4559: 1827, 228: 1828, 1603: 1829, 4976: 1830, 4462: 1831, 3220: 1832, 4544: 1833, 389: 1834, 3212: 1835, 793: 1836, 1872: 1837, 4325: 1838, 2123: 1839, 4294: 1840, 1414: 1841, 4832: 1842, 144: 1843, 2291: 1844, 5429: 1845, 701: 1846, 2092: 1847, 1145: 1848, 3288: 1849, 3925: 1850, 4758: 1851, 3239: 1852, 4724: 1853, 2540: 1854, 4402: 1855, 2025: 1856, 5067: 1857, 1951: 1858, 747: 1859, 2864: 1860, 5538: 1861, 3997: 1862, 424: 1863, 3317: 1864, 2959: 1865, 1949: 1866, 3189: 1867, 1811: 1868, 4028: 1869, 3899: 1870, 3115: 1871, 1506: 1872, 1086: 1873, 4789: 1874, 3497: 1875, 1844: 1876, 1423: 1877, 1946: 1878, 1546: 1879, 3112: 1880, 581: 1881, 2558: 1882, 1004: 1883, 1480: 1884, 3863: 1885, 4702: 1886, 4314: 1887, 497: 1888, 1278: 1889, 4871: 1890, 2287: 1891, 2406: 1892, 2364: 1893, 1290: 1894, 5561: 1895, 2004: 1896, 3219: 1897, 358: 1898, 5216: 1899, 1998: 1900, 3046: 1901, 5349: 1902, 5456: 1903, 627: 1904, 5097: 1905, 4086: 1906, 3514: 1907, 2542: 1908, 5539: 1909, 3772: 1910, 11: 1911, 657: 1912, 5100: 1913, 1376: 1914, 4254: 1915, 1602: 1916, 359: 1917, 2698: 1918, 3576: 1919, 4310: 1920, 4670: 1921, 1675: 1922, 5477: 1923, 2850: 1924, 4185: 1925, 193: 1926, 792: 1927, 2409: 1928, 4227: 1929, 1339: 1930, 5059: 1931, 3780: 1932, 3950: 1933, 1720: 1934, 2742: 1935, 438: 1936, 2126: 1937, 2080: 1938, 935: 1939, 3919: 1940, 4717: 1941, 3794: 1942, 2637: 1943, 970: 1944, 4022: 1945, 1838: 1946, 4572: 1947, 1140: 1948, 5077: 1949, 5578: 1950, 5068: 1951, 4701: 1952, 3827: 1953, 4579: 1954, 4509: 1955, 5600: 1956, 5496: 1957, 263: 1958, 1418: 1959, 5355: 1960, 5405: 1961, 483: 1962, 2912: 1963, 3749: 1964, 3734: 1965, 2299: 1966, 1168: 1967, 3677: 1968, 3981: 1969, 4727: 1970, 894: 1971, 1426: 1972, 422: 1973, 799: 1974, 412: 1975, 2745: 1976, 2714: 1977, 45: 1978, 5016: 1979, 818: 1980, 5505: 1981, 758: 1982, 4977: 1983, 2060: 1984, 1719: 1985, 4534: 1986, 782: 1987, 963: 1988, 1307: 1989, 5285: 1990, 5122: 1991, 4779: 1992, 2443: 1993, 3104: 1994, 546: 1995, 633: 1996, 5092: 1997, 1392: 1998, 1664: 1999, 4068: 2000, 5096: 2001, 3924: 2002, 1519: 2003, 1878: 2004, 3158: 2005, 4387: 2006, 4016: 2007, 2606: 2008, 3329: 2009, 4363: 2010, 4108: 2011, 1433: 2012, 207: 2013, 1053: 2014, 1963: 2015, 1696: 2016, 3954: 2017, 658: 2018, 4374: 2019, 5028: 2020, 15: 2021, 4632: 2022, 3043: 2023, 4830: 2024, 1023: 2025, 1003: 2026, 4587: 2027, 246: 2028, 2677: 2029, 5568: 2030, 5322: 2031, 5187: 2032, 5021: 2033, 4464: 2034, 4945: 2035, 2846: 2036, 478: 2037, 2765: 2038, 2490: 2039, 3771: 2040, 5209: 2041, 831: 2042, 2813: 2043, 2202: 2044, 5317: 2045, 191: 2046, 5: 2047, 180: 2048, 5411: 2049, 3398: 2050, 4240: 2051, 977: 2052, 1535: 2053, 2034: 2054, 3152: 2055, 4672: 2056, 2729: 2057, 2401: 2058, 2266: 2059, 5404: 2060, 979: 2061, 1587: 2062, 1327: 2063, 1459: 2064, 2363: 2065, 3812: 2066, 4938: 2067, 5369: 2068, 3630: 2069, 909: 2070, 271: 2071, 551: 2072, 5541: 2073, 1042: 2074, 1384: 2075, 4580: 2076, 2334: 2077, 1301: 2078, 1979: 2079, 5543: 2080, 1530: 2081, 66: 2082, 4359: 2083, 2196: 2084, 2482: 2085, 2278: 2086, 926: 2087, 4118: 2088, 877: 2089, 1218: 2090, 3718: 2091, 4057: 2092, 3585: 2093, 4834: 2094, 3190: 2095, 5601: 2096, 5360: 2097, 265: 2098, 3914: 2099, 4151: 2100, 1306: 2101, 2439: 2102, 3567: 2103, 42: 2104, 5259: 2105, 2868: 2106, 341: 2107, 221: 2108, 845: 2109, 4890: 2110, 3797: 2111, 3607: 2112, 1632: 2113, 3824: 2114, 4958: 2115, 1752: 2116, 1025: 2117, 1113: 2118, 2991: 2119, 4104: 2120, 4541: 2121, 796: 2122, 4528: 2123, 5128: 2124, 214: 2125, 4666: 2126, 110: 2127, 335: 2128, 1263: 2129, 2507: 2130, 2778: 2131, 2077: 2132, 712: 2133, 3234: 2134, 2255: 2135, 2367: 2136, 1247: 2137, 3782: 2138, 574: 2139, 1389: 2140, 3474: 2141, 3568: 2142, 1164: 2143, 2189: 2144, 5332: 2145, 576: 2146, 534: 2147, 2839: 2148, 4950: 2149, 3768: 2150, 4660: 2151, 5609: 2152, 3759: 2153, 3130: 2154, 2986: 2155, 4831: 2156, 4223: 2157, 1074: 2158, 1321: 2159, 4906: 2160, 2071: 2161, 993: 2162, 4915: 2163, 1517: 2164, 2836: 2165, 5484: 2166, 4685: 2167, 1612: 2168, 5613: 2169, 1827: 2170, 5440: 2171, 1262: 2172, 3155: 2173, 2879: 2174, 1130: 2175, 1846: 2176, 1458: 2177, 1385: 2178, 4460: 2179, 3345: 2180, 5464: 2181, 3517: 2182, 1094: 2183, 4586: 2184, 3019: 2185, 3731: 2186, 4352: 2187, 4927: 2188, 2835: 2189, 2283: 2190, 1039: 2191, 57: 2192, 5164: 2193, 5498: 2194, 4190: 2195, 4423: 2196, 2068: 2197, 3550: 2198, 5616: 2199, 2806: 2200, 4641: 2201, 463: 2202, 1787: 2203, 2795: 2204, 2944: 2205, 2788: 2206, 1358: 2207, 2777: 2208, 3977: 2209, 4545: 2210, 4517: 2211, 5393: 2212, 2511: 2213, 2378: 2214, 966: 2215, 1779: 2216, 1882: 2217, 3703: 2218, 2508: 2219, 4307: 2220, 4025: 2221, 4290: 2222, 2356: 2223, 1471: 2224, 60: 2225, 4935: 2226, 1520: 2227, 1817: 2228, 2977: 2229, 5043: 2230, 4797: 2231, 1697: 2232, 588: 2233, 1071: 2234, 3764: 2235, 1781: 2236, 64: 2237, 5151: 2238, 1712: 2239, 4557: 2240, 107: 2241, 3895: 2242, 4450: 2243, 2638: 2244, 2515: 2245, 4405: 2246, 4434: 2247, 1205: 2248, 2666: 2249, 258: 2250, 1239: 2251, 3251: 2252, 1955: 2253, 2341: 2254, 139: 2255, 1192: 2256, 5206: 2257, 2560: 2258, 250: 2259, 4433: 2260, 1904: 2261, 665: 2262, 978: 2263, 5036: 2264, 2132: 2265, 1692: 2266, 1764: 2267, 3968: 2268, 4020: 2269, 4401: 2270, 2343: 2271, 1102: 2272, 1100: 2273, 5037: 2274, 1644: 2275, 260: 2276, 3710: 2277, 3263: 2278, 3441: 2279, 3083: 2280, 3105: 2281, 4990: 2282, 824: 2283, 5258: 2284, 2022: 2285, 2504: 2286, 1541: 2287, 337: 2288, 2952: 2289, 2087: 2290, 1646: 2291, 3144: 2292, 3221: 2293, 3741: 2294, 3978: 2295, 2326: 2296, 2053: 2297, 2494: 2298, 2423: 2299, 4564: 2300, 4386: 2301, 1551: 2302, 5191: 2303, 3526: 2304, 1855: 2305, 4778: 2306, 429: 2307, 3926: 2308, 4651: 2309, 4877: 2310, 3803: 2311, 113: 2312, 2916: 2313, 477: 2314, 2137: 2315, 2273: 2316, 791: 2317, 4768: 2318, 4436: 2319, 5117: 2320, 1841: 2321, 1125: 2322, 4659: 2323, 1705: 2324, 4997: 2325, 2624: 2326, 5545: 2327, 4289: 2328, 3523: 2329, 3967: 2330, 5065: 2331, 5503: 2332, 2954: 2333, 2358: 2334, 1017: 2335, 5412: 2336, 5356: 2337, 5017: 2338, 3174: 2339, 3996: 2340, 1450: 2341, 2512: 2342, 2927: 2343, 918: 2344, 5544: 2345, 2798: 2346, 2388: 2347, 2710: 2348, 2017: 2349, 618: 2350, 1261: 2351, 425: 2352, 326: 2353, 4628: 2354, 1456: 2355, 373: 2356, 4614: 2357, 316: 2358, 1968: 2359, 5450: 2360, 2981: 2361, 3198: 2362, 305: 2363, 520: 2364, 2562: 2365, 4050: 2366, 1596: 2367, 4615: 2368, 5619: 2369, 1149: 2370, 3167: 2371, 1110: 2372, 5408: 2373, 4208: 2374, 2136: 2375, 236: 2376, 1257: 2377, 3455: 2378, 2733: 2379, 821: 2380, 3558: 2381, 2750: 2382, 3641: 2383, 2728: 2384, 1258: 2385, 4848: 2386, 3379: 2387, 1479: 2388, 101: 2389, 1511: 2390, 1568: 2391, 952: 2392, 4678: 2393, 3654: 2394, 3612: 2395, 858: 2396, 5303: 2397, 5506: 2398, 4842: 2399, 3493: 2400, 2899: 2401, 4083: 2402, 3311: 2403, 740: 2404, 5004: 2405, 1746: 2406, 976: 2407, 1378: 2408, 3617: 2409, 1122: 2410, 1496: 2411, 4867: 2412, 1056: 2413, 4311: 2414, 1355: 2415, 3605: 2416, 3347: 2417, 5238: 2418, 4202: 2419, 3632: 2420, 4745: 2421, 1167: 2422, 559: 2423, 304: 2424, 5540: 2425, 3934: 2426, 3908: 2427, 4216: 2428, 1107: 2429, 2476: 2430, 5533: 2431, 162: 2432, 2316: 2433, 1637: 2434, 5171: 2435, 3621: 2436, 5384: 2437, 3505: 2438, 4574: 2439, 68: 2440, 5331: 2441, 3791: 2442, 3757: 2443, 5202: 2444, 1902: 2445, 1539: 2446, 578: 2447, 3609: 2448, 2172: 2449, 1243: 2450, 3274: 2451, 2246: 2452, 5390: 2453, 3178: 2454, 5608: 2455, 1088: 2456, 1474: 2457, 4738: 2458, 3005: 2459, 5027: 2460, 4427: 2461, 4026: 2462, 1934: 2463, 1584: 2464, 4391: 2465, 3548: 2466, 3725: 2467, 2274: 2468, 3326: 2469, 778: 2470, 3852: 2471, 35: 2472, 3129: 2473, 4613: 2474, 4284: 2475, 2382: 2476, 3344: 2477, 5160: 2478, 4776: 2479, 1693: 2480, 3485: 2481, 549: 2482, 4267: 2483, 2882: 2484, 1027: 2485, 3110: 2486, 2596: 2487, 1379: 2488, 4604: 2489, 3406: 2490, 4353: 2491, 2974: 2492, 5031: 2493, 519: 2494, 1674: 2495, 3147: 2496, 640: 2497, 1397: 2498, 3470: 2499, 2173: 2500, 2108: 2501, 1829: 2502, 5089: 2503, 3131: 2504, 1635: 2505, 3458: 2506, 406: 2507, 74: 2508, 3275: 2509, 681: 2510, 810: 2511, 4045: 2512, 991: 2513, 2078: 2514, 5267: 2515, 3637: 2516, 1974: 2517, 136: 2518, 188: 2519, 2945: 2520, 5512: 2521, 2082: 2522, 4525: 2523, 1942: 2524, 1653: 2525, 587: 2526, 1760: 2527, 1421: 2528, 4100: 2529, 2783: 2530, 2230: 2531, 4486: 2532, 2452: 2533, 5091: 2534, 1630: 2535, 2493: 2536, 1049: 2537, 4800: 2538, 3988: 2539, 2712: 2540, 4661: 2541, 4754: 2542, 1995: 2543, 4600: 2544, 4638: 2545, 3240: 2546, 4887: 2547, 437: 2548, 362: 2549, 568: 2550, 2180: 2551, 3856: 2552, 919: 2553, 2674: 2554, 2019: 2555, 3196: 2556, 2590: 2557, 4403: 2558, 5156: 2559, 4699: 2560, 1099: 2561, 5492: 2562, 941: 2563, 3570: 2564, 3884: 2565, 4752: 2566, 5311: 2567, 2534: 2568, 1085: 2569, 4828: 2570, 2854: 2571, 4439: 2572, 1235: 2573, 4126: 2574, 5400: 2575, 3217: 2576, 2456: 2577, 2241: 2578, 5061: 2579, 3763: 2580, 5070: 2581, 1807: 2582, 1356: 2583, 4957: 2584, 4167: 2585, 4707: 2586, 3316: 2587, 3459: 2588, 5363: 2589, 3760: 2590, 2167: 2591, 3613: 2592, 2754: 2593, 4478: 2594, 4483: 2595, 5169: 2596, 1191: 2597, 307: 2598, 3635: 2599, 2569: 2600, 724: 2601, 563: 2602, 4682: 2603, 1187: 2604, 5269: 2605, 3279: 2606, 2726: 2607, 3244: 2608, 3951: 2609, 4: 2610, 3672: 2611, 4271: 2612, 2192: 2613, 1599: 2614, 1195: 2615, 1467: 2616, 2194: 2617, 2234: 2618, 320: 2619, 4413: 2620, 158: 2621, 3542: 2622, 2938: 2623, 4447: 2624, 3702: 2625, 2544: 2626, 3353: 2627, 3006: 2628, 3368: 2629, 2130: 2630, 135: 2631, 5177: 2632, 4900: 2633, 5387: 2634, 2387: 2635, 484: 2636, 4246: 2637, 4611: 2638, 2565: 2639, 3370: 2640, 2767: 2641, 1402: 2642, 1453: 2643, 1753: 2644, 3880: 2645, 4114: 2646, 2389: 2647, 4315: 2648, 2840: 2649, 142: 2650, 286: 2651, 4030: 2652, 2570: 2653, 4712: 2654, 5260: 2655, 3183: 2656, 4243: 2657, 2529: 2658, 3163: 2659, 1834: 2660, 4139: 2661, 3282: 2662, 4231: 2663, 2664: 2664, 3391: 2665, 3363: 2666, 1997: 2667, 4368: 2668, 5417: 2669, 2024: 2670, 1875: 2671, 3113: 2672, 5481: 2673, 1572: 2674, 3663: 2675, 4196: 2676, 1932: 2677, 4740: 2678, 3886: 2679, 4322: 2680, 1347: 2681, 687: 2682, 3237: 2683, 4873: 2684, 2681: 2685, 3534: 2686, 3430: 2687, 407: 2688, 492: 2689, 4233: 2690, 2298: 2691, 2383: 2692, 2688: 2693, 580: 2694, 4035: 2695, 4133: 2696, 5326: 2697, 5338: 2698, 2212: 2699, 1180: 2700, 4793: 2701, 491: 2702, 3498: 2703, 372: 2704, 555: 2705, 5008: 2706, 1486: 2707, 982: 2708, 1726: 2709, 4520: 2710, 224: 2711, 2934: 2712, 4940: 2713, 2774: 2714, 2588: 2715, 2978: 2716, 615: 2717, 5486: 2718, 2447: 2719, 5198: 2720, 4677: 2721, 3922: 2722, 5344: 2723, 4230: 2724, 3681: 2725, 2349: 2726, 4002: 2727, 1305: 2728, 3047: 2729, 1425: 2730, 5548: 2731, 4069: 2732, 378: 2733, 2340: 2734, 2450: 2735, 1738: 2736, 5615: 2737, 2884: 2738, 2313: 2739, 5566: 2740, 4135: 2741, 4342: 2742, 3765: 2743, 1912: 2744, 5219: 2745, 3338: 2746, 1658: 2747, 4276: 2748, 4694: 2749, 3838: 2750, 3701: 2751, 3799: 2752, 694: 2753, 4667: 2754, 596: 2755, 720: 2756, 2998: 2757, 3578: 2758, 4093: 2759, 3804: 2760, 1835: 2761, 1396: 2762, 1910: 2763, 3602: 2764, 360: 2765, 3821: 2766, 3633: 2767, 3422: 2768, 2049: 2769, 5490: 2770, 3932: 2771, 1907: 2772, 3704: 2773, 4536: 2774, 211: 2775, 823: 2776, 106: 2777, 4252: 2778, 1058: 2779, 1510: 2780, 5597: 2781, 1711: 2782, 636: 2783, 1144: 2784, 1330: 2785, 5570: 2786, 1002: 2787, 732: 2788, 1650: 2789, 4576: 2790, 1007: 2791, 3480: 2792, 1104: 2793, 2174: 2794, 3675: 2795, 1909: 2796, 2117: 2797, 1944: 2798, 1024: 2799, 5354: 2800, 3446: 2801, 4771: 2802, 1731: 2803, 128: 2804, 1267: 2805, 3800: 2806, 5432: 2807, 1832: 2808, 387: 2809, 3107: 2810, 3090: 2811, 2184: 2812, 891: 2813, 2756: 2814, 5131: 2815, 3073: 2816, 2428: 2817, 5249: 2818, 1964: 2819, 297: 2820, 1893: 2821, 3236: 2822, 839: 2823, 2099: 2824, 1303: 2825, 1749: 2826, 4506: 2827, 3536: 2828, 4005: 2829, 2111: 2830, 2183: 2831, 4583: 2832, 5352: 2833, 4737: 2834, 5480: 2835, 717: 2836, 67: 2837, 152: 2838, 5242: 2839, 4383: 2840, 1983: 2841, 3160: 2842, 333: 2843, 3216: 2844, 3792: 2845, 2656: 2846, 91: 2847, 3494: 2848, 3845: 2849, 5213: 2850, 579: 2851, 2577: 2852, 1730: 2853, 1236: 2854, 2109: 2855, 5423: 2856, 663: 2857, 3491: 2858, 1601: 2859, 4961: 2860, 1146: 2861, 4821: 2862, 4159: 2863, 586: 2864, 7: 2865, 4675: 2866, 1748: 2867, 1828: 2868, 209: 2869, 5488: 2870, 4411: 2871, 212: 2872, 1789: 2873, 2592: 2874, 3028: 2875, 2403: 2876, 2894: 2877, 3077: 2878, 678: 2879, 4523: 2880, 5509: 2881, 1863: 2882, 4889: 2883, 306: 2884, 3226: 2885, 1926: 2886, 4951: 2887, 1416: 2888, 3927: 2889, 1497: 2890, 3094: 2891, 2913: 2892, 4285: 2893, 3339: 2894, 5515: 2895, 3581: 2896, 4060: 2897, 951: 2898, 2877: 2899, 2831: 2900, 765: 2901, 3138: 2902, 508: 2903, 5228: 2904, 2878: 2905, 2873: 2906, 2023: 2907, 4838: 2908, 5034: 2909, 3424: 2910, 1639: 2911, 4540: 2912, 242: 2913, 357: 2914, 1363: 2915, 5121: 2916, 843: 2917, 5312: 2918, 5256: 2919, 2106: 2920, 3684: 2921, 4091: 2922, 2259: 2923, 2205: 2924, 5471: 2925, 4043: 2926, 937: 2927, 652: 2928, 653: 2929, 54: 2930, 1038: 2931, 2063: 2932, 565: 2933, 2310: 2934, 749: 2935, 682: 2936, 3556: 2937, 276: 2938, 2491: 2939, 4570: 2940, 790: 2941, 2964: 2942, 3255: 2943, 5435: 2944, 338: 2945, 598: 2946, 645: 2947, 3955: 2948, 3088: 2949, 2608: 2950, 426: 2951, 904: 2952, 1054: 2953, 942: 2954, 4228: 2955, 1260: 2956, 1296: 2957, 4843: 2958, 4027: 2959, 3835: 2960, 540: 2961, 5287: 2962, 3214: 2963, 5234: 2964, 4471: 2965, 3256: 2966, 5055: 2967, 3358: 2968, 955: 2969, 4105: 2970, 4201: 2971, 3770: 2972, 434: 2973, 2551: 2974, 910: 2975, 3686: 2976, 859: 2977, 1971: 2978, 1148: 2979, 2535: 2980, 564: 2981, 1759: 2982, 899: 2983, 3035: 2984, 3173: 2985, 5136: 2986, 84: 2987, 861: 2988, 4773: 2989, 3432: 2990, 417: 2991, 3360: 2992, 1642: 2993, 3040: 2994, 1443: 2995, 4763: 2996, 5436: 2997, 1737: 2998, 3266: 2999, 625: 3000, 3890: 3001, 3448: 3002, 5264: 3003, 3375: 3004, 23: 3005, 4354: 3006, 2232: 3007, 392: 3008, 2601: 3009, 4128: 3010, 4029: 3011, 4739: 3012, 4501: 3013, 927: 3014, 2789: 3015, 5173: 3016, 402: 3017, 971: 3018, 1722: 3019, 3272: 3020, 2553: 3021, 851: 3022, 3582: 3023, 5158: 3024, 939: 3025, 1288: 3026, 4336: 3027, 3252: 3028, 3111: 3029, 1343: 3030, 3540: 3031, 1798: 3032, 5038: 3033, 4454: 3034, 2791: 3035, 5398: 3036, 1806: 3037, 3165: 3038, 5421: 3039, 2323: 3040, 5379: 3041, 1597: 3042, 5434: 3043, 526: 3044, 4147: 3045, 2251: 3046, 325: 3047, 1373: 3048, 923: 3049, 829: 3050, 2067: 3051, 2790: 3052, 4697: 3053, 134: 3054, 2958: 3055, 5614: 3056, 2328: 3057, 748: 3058, 3103: 3059, 3929: 3060, 4451: 3061, 5299: 3062, 5045: 3063, 2786: 3064, 3660: 3065, 164: 3066, 2198: 3067, 4389: 3068, 1765: 3069, 442: 3070, 2715: 3071, 3864: 3072, 655: 3073, 834: 3074, 2440: 3075, 3009: 3076, 3195: 3077, 343: 3078, 4966: 3079, 41: 3080, 4649: 3081, 3957: 3082, 4385: 3083, 4928: 3084, 3253: 3085, 5449: 3086, 4630: 3087, 2709: 3088, 2976: 3089, 1537: 3090, 3109: 3091, 5531: 3092, 567: 3093, 2708: 3094, 2792: 3095, 2785: 3096, 4164: 3097, 48: 3098, 4438: 3099, 4589: 3100, 2289: 3101, 218: 3102, 5504: 3103, 2483: 3104, 5162: 3105, 876: 3106, 4009: 3107, 5562: 3108, 2902: 3109, 2955: 3110, 38: 3111, 961: 3112, 4056: 3113, 5250: 3114, 1790: 3115, 3882: 3116, 530: 3117, 3527: 3118, 4191: 3119, 3700: 3120, 1633: 3121, 3881: 3122, 2722: 3123, 2249: 3124, 4538: 3125, 2292: 3126, 5489: 3127, 4663: 3128, 3984: 3129, 621: 3130, 3426: 3131, 1437: 3132, 163: 3133, 1174: 3134, 1514: 3135, 2416: 3136, 3854: 3137, 3591: 3138, 3501: 3139, 1310: 3140, 3840: 3141, 2404: 3142, 1345: 3143, 5297: 3144, 5080: 3145, 5012: 3146, 1455: 3147, 5082: 3148, 2716: 3149, 4795: 3150, 13: 3151, 3000: 3152, 1394: 3153, 5290: 3154, 3705: 3155, 382: 3156, 1083: 3157, 5222: 3158, 4987: 3159, 2651: 3160, 989: 3161, 541: 3162, 1690: 3163, 1930: 3164, 1051: 3165, 4463: 3166, 2436: 3167, 2007: 3168, 1901: 3169, 5403: 3170, 3464: 3171, 2584: 3172, 973: 3173, 1874: 3174, 3587: 3175, 3478: 3176, 3691: 3177, 5042: 3178, 411: 3179, 50: 3180, 878: 3181, 3592: 3182, 1758: 3183, 3031: 3184, 5556: 3185, 4351: 3186, 5493: 3187, 3352: 3188, 940: 3189, 3847: 3190, 329: 3191, 3376: 3192, 3785: 3193, 5610: 3194, 2699: 3195, 2069: 3196, 1200: 3197, 4327: 3198, 1721: 3199, 5284: 3200, 2833: 3201, 2648: 3202, 4297: 3203, 1552: 3204, 3171: 3205, 3145: 3206, 5522: 3207, 4964: 3208, 5211: 3209, 2250: 3210, 3489: 3211, 3735: 3212, 4769: 3213, 4157: 3214, 4619: 3215, 2963: 3216, 755: 3217, 2961: 3218, 155: 3219, 959: 3220, 2530: 3221, 3790: 3222, 2683: 3223, 4279: 3224, 4380: 3225, 2992: 3226, 3162: 3227, 2070: 3228, 1501: 3229, 274: 3230, 1300: 3231, 4384: 3232, 812: 3233, 2645: 3234, 5124: 3235, 771: 3236, 3327: 3237, 287: 3238, 375: 3239, 531: 3240, 4193: 3241, 3891: 3242, 3146: 3243, 1139: 3244, 1388: 3245, 5605: 3246, 3373: 3247, 915: 3248, 1727: 3249, 3056: 3250, 2157: 3251, 4858: 3252, 1476: 3253, 4955: 3254, 4288: 3255, 5278: 3256, 4721: 3257, 542: 3258, 4273: 3259, 4686: 3260, 5565: 3261, 2166: 3262, 3299: 3263, 2770: 3264, 4343: 3265, 3248: 3266, 2332: 3267, 1571: 3268, 3674: 3269, 1809: 3270, 1527: 3271, 5073: 3272, 4148: 3273, 5348: 3274, 156: 3275, 4153: 3276, 1524: 3277, 1515: 3278, 3055: 3279, 4406: 3280, 5559: 3281, 5239: 3282, 261: 3283, 1858: 3284, 4689: 3285, 4023: 3286, 51: 3287, 4212: 3288, 1204: 3289, 364: 3290, 1132: 3291, 2685: 3292, 4959: 3293, 4637: 3294, 5204: 3295, 4735: 3296, 4731: 3297, 2555: 3298, 5306: 3299, 2520: 3300, 4331: 3301, 573: 3302, 4103: 3303, 3002: 3304, 4036: 3305, 2897: 3306, 3294: 3307, 3486: 3308, 3733: 3309, 866: 3310, 1040: 3311, 132: 3312, 1676: 3313, 4379: 3314, 4051: 3315, 1214: 3316, 368: 3317, 16: 3318, 1495: 3319, 2012: 3320, 703: 3321, 814: 3322, 3657: 3323, 1201: 3324, 3233: 3325, 476: 3326, 3947: 3327, 19: 3328, 3628: 3329, 738: 3330, 5110: 3331, 3181: 3332, 4899: 3333, 244: 3334, 3793: 3335, 5482: 3336, 3680: 3337, 3053: 3338, 475: 3339, 4874: 3340, 205: 3341, 4247: 3342, 138: 3343, 1228: 3344, 401: 3345, 40: 3346, 756: 3347, 1607: 3348, 4440: 3349, 3563: 3350, 5252: 3351, 159: 3352, 4598: 3353, 3392: 3354, 4222: 3355, 957: 3356, 4420: 3357, 4188: 3358, 3980: 3359, 404: 3360, 3490: 3361, 3450: 3362, 5212: 3363, 569: 3364, 4194: 3365, 1896: 3366, 3149: 3367, 2290: 3368, 4235: 3369, 4932: 3370, 561: 3371, 3883: 3372, 480: 3373, 3384: 3374, 1179: 3375, 4652: 3376, 3364: 3377, 24: 3378, 1701: 3379, 3874: 3380, 4599: 3381, 1331: 3382, 3744: 3383, 1424: 3384, 249: 3385, 2692: 3386, 273: 3387, 2386: 3388, 552: 3389, 4924: 3390, 2621: 3391, 3719: 3392, 3278: 3393, 5046: 3394, 4281: 3395, 3137: 3396, 2665: 3397, 1350: 3398, 2514: 3399, 4470: 3400, 5039: 3401, 1129: 3402, 1069: 3403, 641: 3404, 2744: 3405, 5483: 3406, 370: 3407, 126: 3408, 1706: 3409, 1442: 3410, 5051: 3411, 865: 3412, 2352: 3413, 3230: 3414, 502: 3415, 450: 3416, 3082: 3417, 1899: 3418, 3577: 3419, 5542: 3420, 3545: 3421, 4610: 3422, 3156: 3423, 5552: 3424, 3789: 3425, 2271: 3426, 1432: 3427, 5418: 3428, 3971: 3429, 4088: 3430, 1181: 3431, 4160: 3432, 1521: 3433, 4554: 3434, 5207: 3435, 4500: 3436, 194: 3437, 2263: 3438, 1429: 3439, 231: 3440, 1783: 3441, 3860: 3442, 2015: 3443, 1668: 3444, 317: 3445, 2773: 3446, 965: 3447, 4592: 3448, 173: 3449, 4903: 3450, 2810: 3451, 272: 3452, 4136: 3453, 3740: 3454, 4547: 3455, 2568: 3456, 308: 3457, 1851: 3458, 388: 3459, 1460: 3460, 2586: 3461, 1370: 3462, 2723: 3463, 647: 3464, 3201: 3465, 593: 3466, 4590: 3467, 2497: 3468, 1659: 3469, 2010: 3470, 2419: 3471, 2947: 3472, 5126: 3473, 2618: 3474, 490: 3475, 5272: 3476, 174: 3477, 313: 3478, 1070: 3479, 1233: 3480, 3694: 3481, 4309: 3482, 3982: 3483, 3522: 3484, 4996: 3485, 2260: 3486, 2837: 3487, 1708: 3488, 5113: 3489, 3254: 3490, 347: 3491, 2914: 3492, 1333: 3493, 5118: 3494, 5130: 3495, 3506: 3496, 3933: 3497, 1111: 3498, 967: 3499, 708: 3500, 1820: 3501, 2302: 3502, 4498: 3503, 2931: 3504, 5442: 3505, 4835: 3506, 5419: 3507, 1982: 3508, 26: 3509, 4920: 3510, 2574: 3511, 5343: 3512, 1080: 3513, 735: 3514, 5129: 3515, 3969: 3516, 393: 3517, 700: 3518, 516: 3519, 538: 3520, 367: 3521, 2552: 3522, 4480: 3523, 2581: 3524, 3269: 3525, 5572: 3526, 2437: 3527, 493: 3528, 1270: 3529, 550: 3530, 1849: 3531, 3466: 3532, 2149: 3533, 83: 3534, 2122: 3535, 1648: 3536, 441: 3537, 153: 3538, 4780: 3539, 1739: 3540, 1672: 3541, 590: 3542, 872: 3543, 706: 3544, 2086: 3545, 2455: 3546, 4417: 3547, 3273: 3548, 3417: 3549, 1090: 3550, 2585: 3551, 1604: 3552, 3695: 3553, 1246: 3554, 1087: 3555, 2431: 3556, 3092: 3557, 5516: 3558, 3746: 3559, 2832: 3560, 4952: 3561, 3463: 3562, 4004: 3563, 2926: 3564, 192: 3565, 2164: 3566, 750: 3567, 356: 3568, 4367: 3569, 4749: 3570, 1427: 3571, 1318: 3572, 4085: 3573, 1548: 3574, 2229: 3575, 4914: 3576, 1750: 3577, 1415: 3578, 1342: 3579, 1933: 3580, 4849: 3581, 4870: 3582, 1947: 3583, 5454: 3584, 3477: 3585, 4008: 3586, 122: 3587, 4082: 3588, 1879: 3589, 4681: 3590, 2462: 3591, 3372: 3592, 3371: 3593, 2748: 3594, 1886: 3595, 2169: 3596, 4416: 3597, 5274: 3598, 1533: 3599, 726: 3600, 3516: 3601, 3457: 3602, 2948: 3603, 3429: 3604, 4984: 3605, 5007: 3606, 1067: 3607, 5090: 3608, 2848: 3609, 2525: 3610, 3361: 3611, 2084: 3612, 536: 3613, 4601: 3614, 1861: 3615, 614: 3616, 5583: 3617, 1371: 3618, 4636: 3619, 5359: 3620, 933: 3621, 464: 3622, 2866: 3623, 4112: 3624, 2563: 3625, 3399: 3626, 5465: 3627, 849: 3628, 1919: 3629, 2216: 3630, 3010: 3631, 5524: 3632, 1620: 3633, 1735: 3634, 3873: 3635, 1353: 3636, 1958: 3637, 2119: 3638, 2626: 3639, 3: 3640, 5555: 3641, 3667: 3642, 2155: 3643, 3513: 3644, 880: 3645, 2390: 3646, 1709: 3647, 5413: 3648, 1336: 3649, 3601: 3650, 172: 3651, 4931: 3652, 2066: 3653, 2320: 3654, 2652: 3655, 1928: 3656, 1803: 3657, 690: 3658, 3333: 3659, 5279: 3660, 3966: 3661, 4149: 3662, 1594: 3663, 1736: 3664, 1463: 3665, 4905: 3666, 1656: 3667, 688: 3668, 1843: 3669, 2607: 3670, 1106: 3671, 2408: 3672, 2308: 3673, 2518: 3674, 5346: 3675, 3644: 3676, 1367: 3677, 3460: 3678, 3706: 3679, 3696: 3680, 4364: 3681, 5291: 3682, 879: 3683, 1755: 3684, 889: 3685, 239: 3686, 3452: 3687, 1264: 3688, 767: 3689, 4031: 3690, 2663: 3691, 5154: 3692, 2445: 3693, 4855: 3694, 529: 3695, 2965: 3696, 1582: 3697, 179: 3698, 3218: 3699, 683: 3700, 2312: 3701, 4101: 3702, 184: 3703, 772: 3704, 5446: 3705, 3991: 3706, 2821: 3707, 5236: 3708, 642: 3709, 2772: 3710, 5288: 3711, 2032: 3712, 5116: 3713, 1977: 3714, 1609: 3715, 5499: 3716, 256: 3717, 1580: 3718, 2355: 3719, 3213: 3720, 3180: 3721, 2036: 3722, 2531: 3723, 2026: 3724, 5189: 3725, 2365: 3726, 89: 3727, 2543: 3728, 376: 3729, 3876: 3730, 46: 3731, 1118: 3732, 2000: 3733, 5188: 3734, 4277: 3735, 4132: 3736, 5255: 3737, 4982: 3738, 444: 3739, 2669: 3740, 55: 3741, 3488: 3742, 2844: 3743, 2065: 3744, 603: 3745, 4395: 3746, 2426: 3747, 1319: 3748, 2227: 3749, 5330: 3750, 80: 3751, 4869: 3752, 4606: 3753, 1135: 3754, 1917: 3755, 3442: 3756, 4494: 3757, 5371: 3758, 2643: 3759, 4898: 3760, 5289: 3761, 1298: 3762, 4886: 3763, 2042: 3764, 4332: 3765, 4437: 3766, 3383: 3767, 4171: 3768, 3597: 3769, 1941: 3770, 4408: 3771, 2254: 3772, 96: 3773, 685: 3774, 2489: 3775, 4968: 3776, 461: 3777, 4242: 3778, 4518: 3779, 3259: 3780, 5584: 3781, 2372: 3782, 1975: 3783, 3388: 3784, 558: 3785, 1150: 3786, 612: 3787, 5394: 3788, 4801: 3789, 1734: 3790, 1162: 3791, 2909: 3792, 3409: 3793, 2740: 3794, 3247: 3795, 5066: 3796, 4481: 3797, 1945: 3798, 4081: 3799, 752: 3800, 22: 3801, 2411: 3802, 4155: 3803, 208: 3804, 837: 3805, 5409: 3806, 47: 3807, 3276: 3808, 2538: 3809, 5137: 3810, 997: 3811, 892: 3812, 5231: 3813, 4516: 3814, 4299: 3815, 2822: 3816, 2510: 3817, 1531: 3818, 2112: 3819, 295: 3820, 3242: 3821, 669: 3822, 664: 3823, 2746: 3824, 3627: 3825, 709: 3826, 1161: 3827, 5323: 3828, 1276: 3829, 481: 3830, 73: 3831, 1724: 3832, 3270: 3833, 2467: 3834, 4861: 3835, 1119: 3836, 2306: 3837, 351: 3838, 5024: 3839, 5485: 3840, 3999: 3841, 2605: 3842, 1199: 3843, 1332: 3844, 4911: 3845, 1194: 3846, 3985: 3847, 4954: 3848, 4810: 3849, 4550: 3850, 3547: 3851, 4743: 3852, 4872: 3853, 764: 3854, 2420: 3855, 4772: 3856, 4853: 3857, 1133: 3858, 5248: 3859, 5262: 3860, 1441: 3861, 1198: 3862, 4868: 3863, 1673: 3864, 1695: 3865, 3349: 3866, 4584: 3867, 3631: 3868, 4825: 3869, 2751: 3870, 503: 3871, 4214: 3872, 639: 3873, 5321: 3874, 462: 3875, 953: 3876, 2256: 3877, 3042: 3878, 456: 3879, 2043: 3880, 4037: 3881, 3091: 3882, 349: 3883, 2650: 3884, 3907: 3885, 3423: 3886, 4140: 3887, 775: 3888, 296: 3889, 1903: 3890, 2118: 3891, 511: 3892, 123: 3893, 4457: 3894, 3995: 3895, 1615: 3896, 2171: 3897, 4960: 3898, 5314: 3899, 3199: 3900, 1660: 3901, 856: 3902, 1197: 3903, 2960: 3904, 1686: 3905, 1120: 3906, 4003: 3907, 380: 3908, 3945: 3909, 2811: 3910, 1985: 3911, 302: 3912, 4791: 3913, 1420: 3914, 4456: 3915, 1213: 3916, 1715: 3917, 2537: 3918, 4339: 3919, 5367: 3920, 1679: 3921, 1747: 3922, 2083: 3923, 2923: 3924, 5029: 3925, 902: 3926, 5144: 3927, 3902: 3928, 1583: 3929, 2784: 3930, 398: 3931, 4549: 3932, 3148: 3933, 554: 3934, 2987: 3935, 2074: 3936, 631: 3937, 2444: 3938, 363: 3939, 3533: 3940, 3615: 3941, 2717: 3942, 1266: 3943, 623: 3944, 2875: 3945, 5386: 3946, 2253: 3947, 5075: 3948, 2867: 3949, 1035: 3950, 945: 3951, 3751: 3952, 4178: 3953, 659: 3954, 2076: 3955, 5554: 3956, 4995: 3957, 4657: 3958, 1970: 3959, 4491: 3960, 2851: 3961, 409: 3962, 1848: 3963, 2418: 3964, 4111: 3965, 5364: 3966, 1713: 3967, 2474: 3968, 2054: 3969, 607: 3970, 3643: 3971, 5134: 3972, 1631: 3973, 3614: 3974, 92: 3975, 2412: 3976, 2190: 3977, 901: 3978, 3850: 3979, 3959: 3980, 1281: 3981, 1091: 3982, 610: 3983, 3093: 3984, 1618: 3985, 932: 3986, 4221: 3987, 1793: 3988, 3538: 3989, 1557: 3990, 4896: 3991, 4176: 3992, 4442: 3993, 3401: 3994, 5309: 3995, 4200: 3996, 2668: 3997, 964: 3998, 2903: 3999, 5577: 4000, 366: 4001, 3071: 4002, 4170: 4003, 1823: 4004, 5048: 4005, 779: 4006, 3683: 4007, 3846: 4008, 2547: 4009, 3650: 4010, 2539: 4011, 2133: 4012, 3648: 4013, 5076: 4014, 718: 4015, 4032: 4016, 4067: 4017, 1821: 4018, 1950: 4019, 2971: 4020, 3059: 4021, 4012: 4022, 2599: 4023, 3258: 4024, 3456: 4025, 76: 4026, 5320: 4027, 770: 4028, 196: 4029, 969: 4030, 3699: 4031, 5315: 4032, 5623: 4033, 2208: 4034, 2461: 4035, 1297: 4036, 3798: 4037, 3235: 4038, 1221: 4039, 3356: 4040, 1682: 4041, 2682: 4042, 3909: 4043, 105: 4044, 240: 4045, 229: 4046, 2702: 4047, 2376: 4048, 20: 4049, 560: 4050, 1005: 4051, 285: 4052, 315: 4053, 3106: 4054, 638: 4055, 3267: 4056, 4863: 4057, 1605: 4058, 5593: 4059, 1936: 4060, 4808: 4061, 3416: 4062, 489: 4063, 4802: 4064, 4811: 4065, 4607: 4066, 2161: 4067, 2951: 4068, 3308: 4069, 4019: 4070, 1625: 4071, 4885: 4072, 3032: 4073, 769: 4074, 1868: 4075, 5560: 4076, 5624: 4077, 972: 4078, 2690: 4079, 1923: 4080, 4080: 4081, 5057: 4082, 599: 4083, 4021: 4084, 2244: 4085, 759: 4086, 3525: 4087, 4094: 4088, 2151: 4089, 5056: 4090, 1469: 4091, 275: 4092, 1212: 4093, 3467: 4094, 4272: 4095, 5093: 4096, 1248: 4097, 2982: 4098, 1890: 4099, 1528: 4100, 396: 4101, 169: 4102, 3935: 4103, 4629: 4104, 1595: 4105, 3729: 4106, 2050: 4107, 1792: 4108, 5088: 4109, 5114: 4110, 5319: 4111, 3382: 4112, 3238: 4113, 2277: 4114, 2177: 4115, 1015: 4116, 4034: 4117, 656: 4118, 4531: 4119, 2838: 4120, 4445: 4121, 1055: 4122, 4625: 4123, 4983: 4124, 1177: 4125, 3293: 4126, 1126: 4127, 1560: 4128, 5453: 4129, 2434: 4130, 3125: 4131, 4106: 4132, 3072: 4133, 190: 4134, 340: 4135, 5176: 4136, 34: 4137, 4113: 4138, 556: 4139, 3337: 4140, 742: 4141, 458: 4142, 3588: 4143, 334: 4144, 494: 4145, 3825: 4146, 4116: 4147, 2392: 4148, 1558: 4149, 3067: 4150, 1613: 4151, 5508: 4152, 4316: 4153, 1410: 4154, 5183: 4155, 2988: 4156, 500: 4157, 4747: 4158, 1850: 4159, 1284: 4160, 2860: 4161, 4234: 4162, 4705: 4163, 696: 4164, 4775: 4165, 5123: 4166, 1127: 4167, 131: 4168, 1847: 4169, 5032: 4170, 2375: 4171, 255: 4172, 3232: 4173, 3140: 4174, 3161: 4175, 2466: 4176, 2968: 4177, 4847: 4178, 1796: 4179, 4883: 4180, 4719: 4181, 1914: 4182, 807: 4183, 2037: 4184, 2481: 4185, 1304: 4186, 1115: 4187, 56: 4188, 2197: 4189, 3870: 4190, 2295: 4191, 5373: 4192, 2672: 4193, 1325: 4194, 5378: 4195, 986: 4196, 1622: 4197, 1207: 4198, 355: 4199, 2573: 4200, 1683: 4201, 828: 4202, 2220: 4203, 4513: 4204, 2325: 4205, 1542: 4206, 914: 4207, 324: 4208, 1105: 4209, 4593: 4210, 800: 4211, 4857: 4212, 1478: 4213, 3015: 4214, 4533: 4215, 5223: 4216, 5054: 4217, 5574: 4218, 4716: 4219, 5558: 4220, 789: 4221, 4092: 4222, 4767: 4223, 5253: 4224, 3186: 4225, 3021: 4226, 2258: 4227, 3257: 4228, 5447: 4229, 3126: 4230, 2979: 4231, 2496: 4232, 298: 4233, 1240: 4234, 4929: 4235, 1585: 4236, 2231: 4237, 1743: 4238, 3119: 4239, 3033: 4240, 1033: 4241, 2002: 4242, 1006: 4243, 1062: 4244, 1313: 4245, 4495: 4246, 1163: 4247, 2110: 4248, 5495: 4249, 2933: 4250, 1286: 4251, 2995: 4252, 2841: 4253, 1225: 4254, 4679: 4255, 620: 4256, 5368: 4257, 518: 4258, 1028: 4259, 1229: 4260, 4144: 4261, 3762: 4262, 2307: 4263, 4622: 4264, 5178: 4265, 3879: 4266, 4058: 4267, 5286: 4268, 1409: 4269, 4467: 4270, 1774: 4271, 5307: 4272, 3849: 4273, 4238: 4274, 2410: 4275, 604: 4276, 1036: 4277, 5106: 4278, 4431: 4279, 825: 4280, 4635: 4281, 4999: 4282, 321: 4283, 4824: 4284, 2639: 4285, 469: 4286, 4488: 4287, 6: 4288, 3892: 4289, 649: 4290, 37: 4291, 235: 4292, 2134: 4293, 3079: 4294, 1785: 4295, 2826: 4296, 2695: 4297, 2178: 4298, 270: 4299, 17: 4300, 4049: 4301, 4757: 4302, 2524: 4303, 5392: 4304, 2804: 4305, 39: 4306, 4856: 4307, 900: 4308, 95: 4309, 4819: 4310, 4741: 4311, 5530: 4312, 1921: 4313, 311: 4314, 4986: 4315, 2285: 4316, 3062: 4317, 269: 4318, 875: 4319, 3325: 4320, 2463: 4321, 734: 4322, 1499: 4323, 1217: 4324, 2143: 4325, 2035: 4326, 3777: 4327, 1112: 4328, 2517: 4329, 2269: 4330, 2975: 4331, 4939: 4332, 2604: 4333, 5152: 4334, 5501: 4335, 5112: 4336, 3714: 4337, 147: 4338, 2610: 4339, 3603: 4340, 27: 4341, 384: 4342, 1525: 4343, 1249: 4344, 452: 4345, 5334: 4346, 2602: 4347, 3011: 4348, 1661: 4349, 327: 4350, 5587: 4351, 4125: 4352, 5148: 4353, 5396: 4354, 3135: 4355, 3475: 4356, 2142: 4357, 2929: 4358, 2528: 4359, 2889: 4360, 79: 4361, 2509: 4362, 4446: 4363, 2200: 4364, 1280: 4365, 3839: 4366, 3397: 4367, 4305: 4368, 2823: 4369, 5518: 4370, 3324: 4371, 5526: 4372, 1014: 4373, 3898: 4374, 1992: 4375, 5175: 4376, 988: 4377, 1026: 4378, 3903: 4379, 5451: 4380, 2448: 4381, 3334: 4382, 405: 4383, 1211: 4384, 4884: 4385, 5537: 4386, 996: 4387, 1772: 4388, 4620: 4389, 1341: 4390, 2243: 4391, 1503: 4392, 543: 4393, 2613: 4394, 3727: 4395, 4875: 4396, 5026: 4397, 1729: 4398, 1870: 4399, 1466: 4400, 12: 4401, 3078: 4402, 3070: 4403, 213: 4404, 1935: 4405, 2381: 4406, 2567: 4407, 3268: 4408, 468: 4409, 5170: 4410, 2470: 4411, 5049: 4412, 4827: 4413, 1242: 4414, 4895: 4415, 4165: 4416, 5430: 4417, 2973: 4418, 1689: 4419, 2707: 4420, 186: 4421, 4084: 4422, 4703: 4423, 1777: 4424, 2990: 4425, 4833: 4426, 2898: 4427, 4836: 4428, 3018: 4429, 5161: 4430, 3310: 4431, 31: 4432, 2579: 4433, 673: 4434, 736: 4435, 3085: 4436, 1114: 4437, 1577: 4438, 4492: 4439, 1763: 4440, 2764: 4441, 1311: 4442, 575: 4443, 5407: 4444, 783: 4445, 2857: 4446, 5579: 4447, 5104: 4448, 200: 4449, 2653: 4450, 3184: 4451, 4720: 4452, 2357: 4453, 4187: 4454, 3298: 4455, 4213: 4456, 4565: 4457, 5302: 4458, 2984: 4459, 729: 4460, 1487: 4461, 3889: 4462, 5020: 4463, 227: 4464, 2319: 4465, 3956: 4466, 4725: 4467, 4245: 4468, 1504: 4469, 2522: 4470, 1220: 4471, 2828: 4472, 2370: 4473, 3682: 4474, 3476: 4475, 1285: 4476, 934: 4477, 2085: 4478, 3336: 4479, 1282: 4480, 3051: 4481, 4466: 4482, 4969: 4483, 3265: 4484, 5581: 4485, 2498: 4486, 5361: 4487, 3690: 4488, 3479: 4489, 595: 4490, 1346: 4491, 617: 4492, 4787: 4493, 1245: 4494, 4219: 4495, 141: 4496, 4841: 4497, 5229: 4498, 1160: 4499, 487: 4500, 2344: 4501, 852: 4502, 1665: 4503, 3284: 4504, 3557: 4505, 2946: 4506, 753: 4507, 2330: 4508, 1825: 4509, 1744: 4510, 4796: 4511, 1093: 4512, 3351: 4513, 2162: 4514, 746: 4515, 1590: 4516, 2755: 4517, 4888: 4518, 5001: 4519, 237: 4520, 5221: 4521, 3410: 4522, 1598: 4523, 4156: 4524, 3983: 4525, 5514: 4526, 572: 4527, 5240: 4528, 3215: 4529, 2281: 4530, 3829: 4531, 4713: 4532, 3510: 4533, 509: 4534, 798: 4535, 2743: 4536, 5079: 4537, 1334: 4538, 4412: 4539, 247: 4540, 2706: 4541, 1818: 4542, 1662: 4543, 2105: 4544, 2058: 4545, 523: 4546, 3600: 4547, 3414: 4548, 2284: 4549, 3865: 4550, 2632: 4551, 3953: 4552, 4985: 4553, 545: 4554, 149: 4555, 2711: 4556, 2286: 4557, 377: 4558, 4143: 4559, 2859: 4560, 3169: 4561, 5511: 4562, 2252: 4563, 1252: 4564, 4109: 4565, 5261: 4566, 4130: 4567, 3304: 4568, 2700: 4569, 3712: 4570, 1957: 4571, 1795: 4572, 2594: 4573, 1884: 4574, 4017: 4575, 1973: 4576, 234: 4577, 2303: 4578, 5119: 4579, 185: 4580, 2432: 4581, 118: 4582, 3584: 4583, 813: 4584, 202: 4585, 795: 4586, 3808: 4587, 1291: 4588, 3819: 4589, 1277: 4590, 4603: 4591, 165: 4592, 3127: 4593, 1611: 4594, 5385: 4595, 361: 4596, 309: 4597, 5383: 4598, 5448: 4599, 2727: 4600, 2165: 4601, 5174: 4602, 1372: 4603, 2402: 4604, 2869: 4605, 4925: 4606, 3039: 4607, 1063: 4608, 1390: 4609, 4723: 4610, 2048: 4611, 4904: 4612, 2627: 4613, 3640: 4614, 88: 4615, 4860: 4616, 445: 4617, 5015: 4618, 9: 4619, 5395: 4620, 418: 4621, 1540: 4622, 4448: 4623, 5420: 4624, 3646: 4625, 3023: 4626, 94: 4627, 1081: 4628, 4468: 4629, 4823: 4630, 2609: 4631, 2261: 4632, 5598: 4633, 3606: 4634, 4765: 4635, 3783: 4636, 5599: 4637, 4388: 4638, 2152: 4639, 2300: 4640, 4535: 4641, 5005: 4642, 2350: 4643, 816: 4644, 3551: 4645, 3833: 4646, 704: 4647, 4301: 4648, 448: 4649, 4623: 4650, 2337: 4651, 3350: 4652, 303: 4653, 5069: 4654, 2980: 4655, 702: 4656, 4422: 4657, 1869: 4658, 4007: 4659, 5280: 4660, 112: 4661, 2317: 4662, 4278: 4663, 3402: 4664, 668: 4665, 5247: 4666, 3139: 4667, 3916: 4668, 4671: 4669, 1645: 4670, 1254: 4671, 447: 4672, 2768: 4673, 431: 4674, 1326: 4675, 1694: 4676, 1929: 4677, 2158: 4678, 1312: 4679, 1169: 4680, 1565: 4681, 1972: 4682, 5589: 4683, 2843: 4684, 757: 4685, 4371: 4686, 841: 4687, 5241: 4688, 3721: 4689, 2880: 4690, 2817: 4691, 5060: 4692, 2222: 4693, 4090: 4694, 5086: 4695, 2453: 4696, 5085: 4697, 5190: 4698, 2858: 4699, 4901: 4700, 3321: 4701, 4198: 4702, 4806: 4703, 893: 4704, 381: 4705, 3769: 4706, 5217: 4707, 5195: 4708, 2787: 4709, 1287: 4710, 5469: 4711, 5208: 4712, 4792: 4713, 3878: 4714, 2176: 4715, 5006: 4716, 1391: 4717, 4805: 4718, 1943: 4719, 632: 4720, 4258: 4721, 1908: 4722, 512: 4723, 3586: 4724, 1430: 4725, 2368: 4726, 3656: 4727, 4581: 4728, 277: 4729, 4419: 4730, 4633: 4731, 3634: 4732, 4542: 4733, 4123: 4734, 686: 4735, 1592: 4736, 2039: 4737, 4163: 4738, 1990: 4739, 61: 4740, 167: 4741, 1079: 4742, 2321: 4743, 3724: 4744, 4818: 4745, 1428: 4746, 4255: 4747, 4692: 4748, 3014: 4749, 3737: 4750, 5445: 4751, 585: 4752, 2314: 4753, 3060: 4754, 4066: 4755, 395: 4756, 4840: 4757, 5606: 4758, 2242: 4759, 3407: 4760, 2829: 4761, 5592: 4762, 222: 4763, 3507: 4764, 4061: 4765, 5458: 4766, 474: 4767, 2820: 4768, 4011: 4769, 3515: 4770, 5108: 4771, 2634: 4772, 4609: 4773, 3170: 4774, 2414: 4775, 1400: 4776, 4597: 4777, 2055: 4778, 4690: 4779, 1449: 4780, 4566: 4781, 1740: 4782, 1564: 4783, 2073: 4784, 654: 4785, 4205: 4786, 4453: 4787, 4646: 4788, 232: 4789, 5182: 4790, 3973: 4791, 5497: 4792, 4024: 4793, 5014: 4794, 383: 4795, 5094: 4796, 3877: 4797, 2116: 4798, 4822: 4799, 2038: 4800, 1012: 4801, 2527: 4802, 2799: 4803, 473: 4804, 1865: 4805, 339: 4806, 3159: 4807, 4537: 4808, 5146: 4809, 1238: 4810, 4071: 4811, 21: 4812, 3671: 4813, 226: 4814, 1404: 4815, 862: 4816, 3120: 4817, 4215: 4818, 371: 4819, 4814: 4820, 1960: 4821, 1762: 4822, 4119: 4823, 3287: 4824, 3228: 4825, 4934: 4826, 4042: 4827, 4552: 4828, 3755: 4829, 842: 4830, 3487: 4831, 2424: 4832, 4162: 4833, 602: 4834, 2442: 4835, 2801: 4836, 3315: 4837, 1669: 4838, 3202: 4839, 63: 4840, 860: 4841, 999: 4842, 836: 4843, 115: 4844, 195: 4845, 496: 4846, 3003: 4847, 3975: 4848, 4519: 4849, 4839: 4850, 553: 4851, 4425: 4852, 5257: 4853, 99: 4854, 2623: 4855, 5099: 4856, 3396: 4857, 616: 4858, 1871: 4859, 2495: 4860, 2842: 4861, 4210: 4862, 883: 4863, 289: 4864, 4777: 4865, 2661: 4866, 1969: 4867, 2129: 4868, 874: 4869, 197: 4870, 1405: 4871, 4595: 4872, 466: 4873, 3689: 4874, 600: 4875, 1559: 4876, 352: 4877, 956: 4878, 1962: 4879, 1393: 4880, 3271: 4881, 4539: 4882, 1329: 4883, 4308: 4884, 3058: 4885, 3826: 4886, 2741: 4887, 4348: 4888, 3095: 4889, 3964: 4890, 1808: 4891, 81: 4892, 4645: 4893, 3673: 4894, 1757: 4895, 4617: 4896, 5019: 4897, 413: 4898, 3728: 4899, 1666: 4900, 4265: 4901, 707: 4902, 2101: 4903, 4485: 4904, 1723: 4905, 3281: 4906, 1769: 4907, 2918: 4908, 4751: 4909, 3206: 4910, 3492: 4911, 3017: 4912, 3844: 4913, 2480: 4914, 1978: 4915, 2541: 4916, 522: 4917, 4409: 4918, 4375: 4919, 4970: 4920, 1046: 4921, 1717: 4922, 4475: 4923, 4096: 4924, 3913: 4925, 3823: 4926, 981: 4927, 4937: 4928, 148: 4929, 1707: 4930, 3231: 4931, 353: 4932, 2150: 4933, 2417: 4934, 5467: 4935, 727: 4936, 2248: 4937, 1745: 4938, 1226: 4939, 3901: 4940, 3866: 4941, 3543: 4942, 4365: 4943, 4530: 4944, 488: 4945, 4665: 4946, 2138: 4947, 2571: 4948, 3427: 4949, 4253: 4950, 3610: 4951, 3346: 4952, 1589: 4953, 4704: 4954, 108: 4955, 5328: 4956, 1362: 4957, 2061: 4958, 5345: 4959, 4881: 4960, 2771: 4961, 5044: 4962, 1075: 4963, 3188: 4964, 2611: 4965, 1380: 4966, 2210: 4967, 4192: 4968, 1142: 4969, 4653: 4970, 3716: 4971, 3449: 4972, 499: 4973, 3443: 4974, 1382: 4975, 761: 4976, 3295: 4977, 4217: 4978, 917: 4979, 2612: 4980, 1131: 4981, 1667: 4982, 2488: 4983, 2950: 4984, 1470: 4985, 3784: 4986, 4555: 4987, 5041: 4988, 2904: 4989, 137: 4990, 4770: 4991, 3387: 4992, 3736: 4993, 5573: 4994, 5072: 4995, 4102: 4996, 1448: 4997, 666: 4998, 5358: 4999, 5406: 5000, 2003: 5001, 3693: 5002, 950: 5003, 4313: 5004, 1751: 5005, 1819: 5006, 867: 5007, 984: 5008, 102: 5009, 3611: 5010, 2684: 5011, 5293: 5012, 2776: 5013, 3481: 5014, 220: 5015, 4341: 5016, 630: 5017, 1323: 5018, 2701: 5019, 5224: 5020, 5138: 5021, 698: 5022, 4399: 5023, 2749: 5024, 2366: 5025, 1813: 5026, 3469: 5027, 745: 5028, 2499: 5029, 3867: 5030, 3541: 5031, 5233: 5032, 4596: 5033, 3645: 5034, 679: 5035, 4236: 5036, 776: 5037, 1566: 5038, 4742: 5039, 5102: 5040, 1224: 5041, 714: 5042, 5590: 5043, 980: 5044, 3319: 5045, 2373: 5046, 3502: 5047, 605: 5048, 1068: 5049, 788: 5050, 3566: 5051, 2940: 5052, 5347: 5053, 693: 5054, 2769: 5055, 5047: 5056, 4182: 5057, 374: 5058, 4304: 5059, 2441: 5060, 2949: 5061, 1315: 5062, 884: 5063, 5172: 5064, 268: 5065, 2548: 5066, 5527: 5067, 1411: 5068, 5476: 5069, 1699: 5070, 3400: 5071, 3444: 5072, 2824: 5073, 3575: 5074, 995: 5075, 2943: 5076, 3175: 5077, 5422: 5078, 1209: 5079, 189: 5080, 2270: 5081, 3544: 5082, 2533: 5083, 1078: 5084, 3191: 5085, 5569: 5086, 5023: 5087, 4926: 5088, 1913: 5089, 4866: 5090, 3519: 5091, 1386: 5092, 2098: 5093, 1255: 5094, 1256: 5095, 2435: 5096, 903: 5097, 2809: 5098, 219: 5099, 1010: 5100, 4674: 5101, 3596: 5102, 127: 5103, 3664: 5104, 3069: 5105, 4355: 5106, 2361: 5107, 826: 5108, 178: 5109, 2272: 5110, 737: 5111, 4127: 5112, 547: 5113, 4654: 5114, 4558: 5115, 4097: 5116, 1629: 5117, 2075: 5118, 4688: 5119, 1294: 5120, 4553: 5121, 4079: 5122, 2: 5123, 635: 5124, 4350: 5125, 1905: 5126, 4684: 5127, 5342: 5128, 2816: 5129, 5428: 5130, 5011: 5131, 4115: 5132, 3348: 5133, 4414: 5134, 3910: 5135, 1324: 5136, 4195: 5137, 5215: 5138, 4912: 5139, 5296: 5140, 330: 5141, 129: 5142, 5594: 5143, 4605: 5144, 2322: 5145, 1574: 5146, 5163: 5147, 3921: 5148, 2937: 5149, 3754: 5150, 521: 5151, 4715: 5152, 4714: 5153, 1816: 5154, 262: 5155, 2545: 5156, 4753: 5157, 1784: 5158, 3331: 5159, 332: 5160, 4909: 5161, 3508: 5162, 2619: 5163, 2293: 5164, 3795: 5165, 1047: 5166, 968: 5167, 3440: 5168, 744: 5169, 3029: 5170, 3758: 5171, 4358: 5172, 3915: 5173, 1493: 5174, 1776: 5175, 871: 5176, 5246: 5177, 3205: 5178, 4415: 5179, 2654: 5180, 1435: 5181, 5547: 5182, 1704: 5183, 4207: 5184, 2893: 5185, 2057: 5186, 2477: 5187, 2262: 5188, 4287: 5189, 2646: 5190, 1166: 5191, 5084: 5192, 5150: 5193, 3810: 5194, 591: 5195, 2805: 5196, 3355: 5197, 3179: 5198, 5139: 5199, 1208: 5200, 1317: 5201, 2051: 5202, 1859: 5203, 3767: 5204, 251: 5205, 4794: 5206, 2351: 5207, 58: 5208, 288: 5209, 5199: 5210, 5295: 5211, 1073: 5212, 2907: 5213, 2399: 5214, 87: 5215, 3622: 5216, 3989: 5217, 4750: 5218, 4048: 5219, 3629: 5220, 3289: 5221, 1797: 5222, 773: 5223, 2758: 5224, 1761: 5225, 3593: 5226, 4733: 5227, 4477: 5228, 922: 5229, 1895: 5230, 1176: 5231, 428: 5232, 2818: 5233, 4700: 5234, 5127: 5235, 4804: 5236, 3335: 5237, 2089: 5238, 1791: 5239, 5205: 5240, 4962: 5241, 4710: 5242, 2454: 5243, 4266: 5244, 5040: 5245, 4728: 5246, 5391: 5247, 3472: 5248, 1512: 5249, 2566: 5250, 1591: 5251, 3246: 5252, 5351: 5253, 5470: 5254, 1856: 5255, 2871: 5256, 2502: 5257, 3897: 5258, 881: 5259, 832: 5260, 4642: 5261, 2881: 5262, 4865: 5263, 32: 5264, 436: 5265, 2429: 5266, 716: 5267, 1911: 5268, 403: 5269, 2888: 5270, 3998: 5271, 3421: 5272, 1767: 5273, 5375: 5274, 2583: 5275, 4942: 5276, 2147: 5277, 1561: 5278, 5013: 5279, 931: 5280, 3208: 5281, 3297: 5282, 1523: 5283, 3389: 5284, 5071: 5285, 3831: 5286, 4490: 5287, 279: 5288, 3309: 5289, 2892: 5290, 2342: 5291, 1619: 5292, 1136: 5293, 1152: 5294, 1116: 5295, 4334: 5296, 4807: 5297, 3403: 5298, 1096: 5299, 5324: 5300, 3330: 5301, 5301: 5302, 161: 5303, 3807: 5304, 4329: 5305, 4184: 5306, 470: 5307, 4264: 5308, 5125: 5309, 609: 5310, 515: 5311, 4658: 5312, 109: 5313, 3290: 5314, 3918: 5315, 4803: 5316, 1108: 5317, 517: 5318, 5155: 5319, 4933: 5320, 4919: 5321, 5553: 5322, 4062: 5323, 2206: 5324, 2145: 5325, 4174: 5326, 4337: 5327, 5462: 5328, 3412: 5329, 2616: 5330, 2659: 5331, 4744: 5332, 182: 5333, 2427: 5334, 535: 5335, 4502: 5336, 3524: 5337, 743: 5338, 2593: 5339, 253: 5340, 1954: 5341, 592: 5342, 544: 5343, 3822: 5344, 3940: 5345, 5397: 5346, 3574: 5347, 3061: 5348, 5381: 5349, 3114: 5350, 1876: 5351, 504: 5352, 882: 5353, 711: 5354, 2226: 5355, 2047: 5356, 2336: 5357, 3638: 5358, 4226: 5359, 369: 5360, 5376: 5361, 946: 5362, 4965: 5363, 1575: 5364, 1688: 5365, 2575: 5366, 1702: 5367, 3054: 5368, 2377: 5369, 4709: 5370, 1687: 5371, 4499: 5372, 4013: 5373, 2486: 5374, 3377: 5375, 4949: 5376, 2353: 5377, 4512: 5378, 201: 5379, 885: 5380, 634: 5381, 4560: 5382, 2762: 5383, 4669: 5384, 4529: 5385, 1714: 5386, 3245: 5387, 4089: 5388, 4813: 5389, 1649: 5390, 5304: 5391, 2576: 5392, 710: 5393, 527: 5394, 3013: 5395, 2780: 5396, 116: 5397, 929: 5398, 3851: 5399, 1915: 5400, 1976: 5401, 1939: 5402, 3832: 5403, 3554: 5404, 5270: 5405, 1302: 5406, 291: 5407, 1289: 5408, 920: 5409, 199: 5410, 629: 5411, 947: 5412, 781: 5413, 2153: 5414, 4393: 5415, 2732: 5416, 3555: 5417, 2737: 5418, 2506: 5419, 954: 5420, 4326: 5421, 3848: 5422, 3374: 5423, 1556: 5424, 672: 5425, 1464: 5426, 3747: 5427, 433: 5428, 1439: 5429, 907: 5430, 1616: 5431, 5203: 5432, 2305: 5433, 69: 5434, 571: 5435, 528: 5436, 3500: 5437, 4361: 5438, 2670: 5439, 2532: 5440, 2718: 5441, 3428: 5442, 5452: 5443, 2062: 5444, 3509: 5445, 628: 5446, 2614: 5447, 3730: 5448, 2697: 5449, 3843: 5450, 4392: 5451, 2228: 5452, 5030: 5453, 4918: 5454, 5586: 5455, 1756: 5456, 5327: 5457, 336: 5458, 2969: 5459, 648: 5460, 5063: 5461, 4241: 5462, 1431: 5463, 4746: 5464, 52: 5465, 4180: 5466, 3766: 5467, 1436: 5468, 5622: 5469, 1265: 5470, 2120: 5471, 1077: 5472, 2970: 5473, 1465: 5474, 5500: 5475, 482: 5476, 1927: 5477, 725: 5478, 379: 5479, 4225: 5480, 3979: 5481, 4320: 5482, 853: 5483, 2775: 5484, 43: 5485, 4781: 5486, 2011: 5487, 721: 5488, 5101: 5489, 4582: 5490, 2834: 5491, 1188: 5492, 3653: 5493, 198: 5494, 786: 5495, 2018: 5496, 4948: 5497, 3413: 5498, 2760: 5499, 3465: 5500, 501: 5501, 485: 5502, 4426: 5503, 2536: 5504, 5433: 5505, 1084: 5506, 847: 5507, 143: 5508, 2484: 5509, 1021: 5510, 2800: 5511, 3512: 5512, 1959: 5513, 346: 5514, 4624: 5515, 2930: 5516, 2154: 5517, 4372: 5518, 2267: 5519, 4349: 5520, 2127: 5521, 3659: 5522, 33: 5523, 1509: 5524, 3447: 5525, 3639: 5526, 1151: 5527, 2905: 5528, 495: 5529, 1223: 5530, 2188: 5531, 3049: 5532, 1215: 5533, 3962: 5534, 3565: 5535, 1170: 5536, 4418: 5537, 97: 5538, 3026: 5539, 506: 5540, 5415: 5541, 4907: 5542, 2802: 5543, 2209: 5544, 1098: 5545, 1072: 5546, 2705: 5547, 3616: 5548, 1685: 5549, 4121: 5550, 1417: 5551, 1138: 5552, 916: 5553, 4693: 5554, 3723: 5555, 1804: 5556, 5563: 5557, 3063: 5558, 2635: 5559, 1158: 5560, 5557: 5561, 3931: 5562, 453: 5563, 1505: 5564, 230: 5565, 2761: 5566, 4366: 5567, 4317: 5568, 2676: 5569, 5184: 5570, 1406: 5571, 4759: 5572, 1980: 5573, 2264: 5574, 4218: 5575, 3036: 5576, 168: 5577, 1567: 5578, 912: 5579, 3814: 5580, 936: 5581, 809: 5582, 4295: 5583, 4292: 5584, 1815: 5585, 4627: 5586, 3717: 5587, 1203: 5588, 3965: 5589, 3141: 5590, 2724: 5591, 5461: 5592, 2598: 5593, 3118: 5594, 4562: 5595, 1196: 5596, 5353: 5597, 75: 5598, 1361: 5599, 3044: 5600, 4232: 5601, 4428: 5602, 5333: 5603, 5604: 5604, 1608: 5605, 3435: 5606, 1387: 5607, 1550: 5608, 1700: 5609, 3994: 5610, 1967: 5611, 888: 5612, 5235: 5613, 1250: 5614, 2852: 5615, 3917: 5616, 3197: 5617, 4378: 5618, 1: 5619, 3715: 5620, 1395: 5621, 4015: 5622, 2235: 5623, 4524: 5624, 1581: 5625}\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join('./data', \"filtered_meta_Electronics_test.json\")\n",
    "df = pd.read_json(path, lines=True)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "tokenized_set = []\n",
    "for index, row in df.iterrows():\n",
    "    tokenized_set.append([tokenizer.encode_plus(row['description'], truncation = True, return_tensors=\"pt\",\n",
    "                                                max_length=512, pad_to_max_length=True), row['salesRank']])\n",
    "\n",
    "dataloader = createDataloader(tokenized_set, config, test=True)\n",
    "print(predict(dataloader))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
